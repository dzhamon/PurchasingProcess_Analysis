"""
    ะะตััะธั v2 ะบะปะฐััะตัะฝะพะณะพ ะฐะฝะฐะปะธะทะฐ. ะฃะฒะตะปะธัะตะฝะพ ะบะพะปะธัะตััะฒะพ ะฟะพะทะฐะทะฐัะตะปะตะน ะดะปั ะบะปะฐััะธัะธะบะฐัะธะธ
"""
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.cluster import KMeans, DBSCAN
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.metrics import silhouette_score
import warnings

warnings.filterwarnings("ignore")


class EnhancedSupplierClusterAnalyzer:
    def __init__(self, df, column_mapping=None):
        self.df = df.copy()
        self.scaler = StandardScaler()
        self.clusters = None
        self.cluster_centers = None

    def prepare_enhanced_supplier_features(self):
        """
        ะะฐััะธัะตะฝะฝะฐั ะฟะพะดะณะพัะพะฒะบะฐ ะฟัะธะทะฝะฐะบะพะฒ ะดะปั ะบะปะฐััะตัะธะทะฐัะธะธ ะฟะพััะฐะฒัะธะบะพะฒ
        """
        print(f"๐ ะะฑัะฐะฑะฐััะฒะฐะตะผ {len(self.df)} ะทะฐะฟะธัะตะน...")
        print(f"๐ ะฃะฝะธะบะฐะปัะฝัั ะฟะพััะฐะฒัะธะบะพะฒ: {self.df['counterparty_name'].nunique()}")
        
        # ัะพะทะดะฐะตะผ ะบะพะฟะธั ะดะฐะฝะฝัั ะดะปั ะพะฑัะฐะฑะพัะบะธ
        df_clean = self.df.copy()
        
        # ะฟัะตะพะฑัะฐะทัะตะผ ัะธัะปะพะฒัะต ะบะพะปะพะฝะบะธ ะฟัะธะฝัะดะธัะตะปัะฝะพ ะฒ ะฟัะฐะฒะธะปัะฝัะน ัะธะฟ
        numeric_columns = [
            "total_contract_amount_eur", "unit_price_eur", "quantity", "delivery_time_days",
            "product_amount", "additional_expenses"
        ]
        # optional_numeric = ['product_amount', 'additional_expenses']

        for col in numeric_columns:
            if col in df_clean.columns:
                df_clean[col] = pd.to_numeric(df_clean[col], errors="coerce")
                print(f"โ ะัะตะพะฑัะฐะทะพะฒะฐะฝะฐ ะพะฟัะธะพะฝะฐะปัะฝะฐั ะบะพะปะพะฝะบะฐ {col}, NaN ะทะฝะฐัะตะฝะธะน: {df_clean[col].isna().sum()}")
                
    
        # ะะฐะฟะพะปะฝัะตะผ NaN ะทะฝะฐัะตะฝะธั ะฝัะปัะผะธ ะดะปั ัะธัะปะตะฝะฝัั ะบะพะปะพะฝะพะบ
        df_clean[numeric_columns] = df_clean[numeric_columns].fillna(0)
        if "product_amount" in df_clean.columns:
            df_clean["product_amount"] = df_clean["product_amount"].fillna(0)
        if "additional_expenses" in df_clean.columns:
            df_clean["additional_expenses"] = df_clean["additional_expenses"].fillna(0)
        
        # ะกะพะทะดะฐะตะผ ัะปะพะฒะฐัั ะฐะณัะตะณะฐัะธะธ ะดะธะฝะฐะผะธัะตัะบะธ
        agg_dict = {
            # ะคะธะฝะฐะฝัะพะฒัะต ะฟะพะบะฐะทะฐัะตะปะธ
            "total_contract_amount_eur": ["sum", "mean", "std", "count", "min", "max"],
            "unit_price_eur": ["mean", "std", "min", "max"],
            # ะัะตะผะตะฝะฝัะต ะฟะพะบะฐะทะฐัะตะปะธ
            "contract_signing_date": ["min", "max"],
            "delivery_time_days": ["mean", "std", "min", "max"],
            # ะะฑัะตะผะฝัะต ะฟะพะบะฐะทะฐัะตะปะธ
            "quantity": ["sum", "mean", "std", "min", "max"],
            # ะะฐะทะฝะพะพะฑัะฐะทะธะต
            "project_name": "nunique",
            "product_name": "nunique",
            "unit": "nunique",
        }
        
        # ะะพะฑะฐะฒะปัะตะผ ะฒ ัะปะพะฒะฐัั ะพะฟัะธะพะฝะฐะปัะฝัะต ะบะพะปะพะฝะบะธ ะตัะปะธ ะพะฝะธ ะตััั
        if "product_amount" in df_clean.columns:
            agg_dict["product_amount"] = ["sum", "mean", "std"]
        if "additional_expenses" in df_clean.columns:
            agg_dict["additional_expenses"] = ["sum", "mean"]
        if "discipline" in df_clean.columns:
            agg_dict["discipline"] = "nunique"
        if "contract_currency" in df_clean.columns:
            agg_dict["contract_currency"] = "nunique"


        # ะัะฝะพะฒะฝัะต ะฐะณัะตะณะฐัะธะธ ะฟะพ ะฟะพััะฐะฒัะธะบะฐะผ
        supplier_stats = (df_clean.groupby('counterparty_name')
                    .agg(agg_dict).reset_index()
                          )
        # ะะพะฑะฐะฒะธะผ ะพัะปะฐะดะพัะฝัั ะธะฝัะพัะผะฐัะธั:
        print("๐ ะัะปะฐะดะบะฐ ะบะพะปะพะฝะพะบ ะฟะพัะปะต ะฐะณัะตะณะฐัะธะธ:")
        print(f"ะคะฐะบัะธัะตัะบะพะต ะบะพะปะธัะตััะฒะพ ะบะพะปะพะฝะพะบ: {len(supplier_stats.columns)}")
        print(f"ะะฐะทะฒะฐะฝะธั ะบะพะปะพะฝะพะบ: {list(supplier_stats.columns)}")
        
        # ะะธะฝะฐะผะธัะตัะบะพะต ัะณะปะฐะถะธะฒะฐะฝะธะต ะฝะฐะทะฒะฐะฝะธะน ะบะพะปะพะฝะพะบ (ะธะท ะผะฝะพะณะพะธะฝะดะตะบัะฝะพะณะพ ััะพะปะฑัะฐ ะดะตะปะฐะตััั ััะพะปะฑะตั ั ะพะดะฝะธะผ ะฝะฐะธะผะตะฝะพะฒะฐะฝะธะตะผ)
        new_columns = []
        for col in supplier_stats.columns:
            if isinstance(col, tuple):
                # ะัะพะฒะตััะตะผ, ััะพ ะบะพััะตะถ ัะพะดะตัะถะธั ะบะฐะบ ะผะธะฝะธะผัะผ ะดะฒะฐ ัะปะตะผะตะฝัะฐ
                if len(col) > 1 and col[1] == "nunique":
                    new_columns.append(f"{col[0]}_count")
                elif len(col) > 1:
                    new_columns.append(f"{col[0]}_{col[1]}")
                else:
                    # ะะฑัะฐะฑะพัะบะฐ ะบะพััะตะถะตะน ั ะพะดะฝะธะผ ัะปะตะผะตะฝัะพะผ, ะตัะปะธ ัะฐะบะธะต ะตััั
                    new_columns.append(col[0])
            else:
                new_columns.append(col)
        supplier_stats.columns = new_columns
        
        
        # ะกะพะทะดะฐะตะผ ะดะพะฟะพะปะฝะธัะตะปัะฝัะต ัะฐััะตัะฝัะต ะฟัะธะทะฝะฐะบะธ
        
        # 1. ะัะตะผะตะฝะฝัะต ะฟัะธะทะฝะฐะบะธ
        supplier_stats["years_active"] = np.maximum(
            (pd.to_datetime(supplier_stats["contract_signing_date_max"])
             - pd.to_datetime(supplier_stats["contract_signing_date_min"])
        ).dt.days / 365.25, 0.1)
        
        supplier_stats["avg_contracts_per_year"] = supplier_stats["total_contract_amount_eur_count"] / (
            supplier_stats["years_active"] + 1
        )
        
        # 2. ะะพะปะฐัะธะปัะฝะพััั ะธ ััะฐะฑะธะปัะฝะพััั
        supplier_stats["price_volatility"] = (
            supplier_stats["unit_price_eur_std"]
            / supplier_stats["unit_price_eur_mean"].replace(0, np.nan)
        ).fillna(0)
        
        supplier_stats["contract_size_volatility"] = (
            supplier_stats["total_contract_amount_eur_std"]
            / supplier_stats["total_contract_amount_eur_sum"].replace(0, np.nan)
        ).fillna(0)
        
        supplier_stats["quantity_volatility"] = (
            supplier_stats["quantity_std"] / supplier_stats["quantity_mean"].replace(0, np.nan)
        ).fillna(0)
        
        supplier_stats["delivery_volatility"] = (
            supplier_stats["delivery_time_days_std"]
            / supplier_stats["delivery_time_days_mean"].replace(0, np.nan)
        ).fillna(0)
        
        # 3. ะะฐะทะผะตั ะธ ะผะฐัััะฐะฑ ะพะฟะตัะฐัะธะน
        supplier_stats["avg_contract_size_rank"] = supplier_stats["total_contract_amount_eur_sum"].rank(
            pct=True
        )
        supplier_stats["total_volume_rank"] = supplier_stats["total_contract_amount_eur_sum"].rank(pct=True)
        
        supplier_stats["contract_size_range"] = (
            supplier_stats["total_contract_amount_eur_max"] - supplier_stats["total_contract_amount_eur_min"]
        )
        
        supplier_stats["price_range"] = (
            supplier_stats["unit_price_eur_max"] - supplier_stats["unit_price_eur_min"]
        )
        
        # 4. ะะฐะทะฝะพะพะฑัะฐะทะธะต ะธ ัะฟะตัะธะฐะปะธะทะฐัะธั
        supplier_stats["diversification_index"] = (
            np.log1p(supplier_stats["project_name_count"])
            * np.log1p(supplier_stats["product_name_count"])
            * np.log1p(supplier_stats["unit_count"])
            * np.log1p(supplier_stats.get("discipline_count", 1))
        ) ** 0.25  # ะะตะพะผะตััะธัะตัะบะพะต ััะตะดะฝะตะต ะดะปั ัะณะปะฐะถะธะฒะฐะฝะธั
        
        supplier_stats["specialization_ratio"] = supplier_stats[
            "total_contract_amount_eur_count"
        ] / supplier_stats["product_name_count"].replace(0, 1)
        
        # 5. ะญััะตะบัะธะฒะฝะพััั ะธ ะฝะฐะดะตะถะฝะพััั
        supplier_stats["delivery_efficiency"] = 1 / (
            supplier_stats["delivery_time_days_mean"] + 1
        )  # ะงะตะผ ะผะตะฝััะต ะฒัะตะผั, ัะตะผ ะฒััะต ัััะตะบัะธะฒะฝะพััั
        
        supplier_stats["contract_consistency"] = 1 / (
            supplier_stats["contract_size_volatility"] + 0.1
        )  # ะงะตะผ ะผะตะฝััะต ะฒะพะปะฐัะธะปัะฝะพััั, ัะตะผ ะฒััะต ะบะพะฝัะธััะตะฝัะฝะพััั
        
        # 6. ะัะฝะพัะธัะตะปัะฝัะต ะฟะพะบะฐะทะฐัะตะปะธ ะดะพะฟะพะปะฝะธัะตะปัะฝัั ัะฐััะพะดะพะฒ (ัะพะปัะบะพ ะตัะปะธ ะบะพะปะพะฝะบะฐ ะตััั)
        if "additional_expenses_sum" in supplier_stats.columns:
            supplier_stats["additional_expenses_ratio"] = (
                supplier_stats["additional_expenses_sum"]
                / supplier_stats["total_contract_amount_eur_sum"].replace(0, np.nan)
            ).fillna(0)
        else:
            supplier_stats["additional_expenses_ratio"] = 0
        
        # 7. ะะฝัะตะฝัะธะฒะฝะพััั ัะฐะฑะพัั
        supplier_stats["avg_quantity_per_contract"] = (
            supplier_stats["quantity_sum"] / supplier_stats["total_contract_amount_eur_count"]
        )
        
        supplier_stats["revenue_per_project"] = supplier_stats["total_contract_amount_eur_sum"] / supplier_stats[
            "project_name_count"].replace(0, 1)
        
        # 8. ะกะตะทะพะฝะฝะพััั ะธ ัะตะณัะปััะฝะพััั (ะตัะปะธ ะตััั ะดะฐะฝะฝัะต ะฟะพ ะผะตัััะฐะผ)
        if len(df_clean) > 100:  # ะขะพะปัะบะพ ะตัะปะธ ะดะพััะฐัะพัะฝะพ ะดะฐะฝะฝัั
            monthly_activity = df_clean.copy()
            monthly_activity["month"] = pd.to_datetime(
                monthly_activity["contract_signing_date"]
            ).dt.month
            monthly_var = (
                monthly_activity.groupby(["counterparty_name", "month"])
                .size()
                .unstack(fill_value=0)
                .var(axis=1)
            )
            supplier_stats.rename(columns={"counterparty_name_": "counterparty_name"}, inplace=True)
            supplier_stats = supplier_stats.merge(
                monthly_var.rename("seasonal_variance").reset_index(),
                on="counterparty_name",
                how="left",
            )
            supplier_stats["seasonal_variance"] = supplier_stats["seasonal_variance"].fillna(0)
        else:
            supplier_stats["seasonal_variance"] = 0
        
        # 9. ะะธัะบ-ะฟะพะบะฐะทะฐัะตะปะธ -
        supplier_stats["single_client_dependency"] = (
            1 / supplier_stats["project_name_count"]  # ะงะตะผ ะผะตะฝััะต ะฟัะพะตะบัะพะฒ, ัะตะผ ะฒััะต ะทะฐะฒะธัะธะผะพััั
        )
        
        supplier_stats["price_stability_score"] = 1 / (supplier_stats["price_volatility"] + 0.1)
        
        # ะะฐะฟะพะปะฝัะตะผ NaN ะทะฝะฐัะตะฝะธั
        supplier_stats = supplier_stats.fillna(0)
        
        # ะะฐะผะตะฝัะตะผ inf ะฝะฐ ะฑะพะปััะธะต ัะธัะปะฐ
        supplier_stats = supplier_stats.replace([np.inf, -np.inf], [999999, -999999])
        
        print(
            f"โ ะกะพะทะดะฐะฝะพ {len(supplier_stats.columns)} ะฟัะธะทะฝะฐะบะพะฒ ะดะปั {len(supplier_stats)} ะฟะพััะฐะฒัะธะบะพะฒ"
        )
        
        return supplier_stats
        
        
        
    def get_enhanced_feature_columns(self):
        """ะะพะทะฒัะฐัะฐะตั ัะปะพะฒะฐัั ะฟัะธะทะฝะฐะบะพะฒ ะดะปั ะบะปะฐััะตัะธะทะฐัะธะธ"""
        
        rename_mapping = {
            "total_contract_amount_eur_sum": "total_volume",
            "total_contract_amount_eur_mean": "avg_contract_value",
            "total_contract_amount_eur_count": "contracts_count",
            "quantity_sum": "total_quantity",
            "quantity_mean": "avg_quantity",
            "unit_price_eur_mean": "avg_unit_price",
            "price_volatility": "price_volatility",
            "price_range": "price_range",
            "unit_price_eur_min": "min_unit_price",
            "unit_price_eur_max": "max_unit_price",
            "contract_size_volatility": "contract_size_volatility",
            "contract_size_range": "contract_size_range",
            "total_contract_amount_eur_min": "min_contract_value",
            "total_contract_amount_eur_max": "max_contract_value",
            "years_active": "years_active",
            "avg_contracts_per_year": "avg_contracts_per_year",
            "delivery_time_days_mean": "avg_delivery_time",
            "delivery_volatility": "delivery_volatility",
            "delivery_time_days_min": "min_delivery_time",
            "delivery_time_days_max": "max_delivery_time",
            "project_name_count": "projects_count",
            "product_name_count": "products_count",
            "unit_count": "units_count",
            "discipline_count": "disciplines_count",
            "diversification_index": "diversification_index",
            "specialization_ratio": "specialization_ratio",
            "delivery_efficiency": "delivery_efficiency",
            "contract_consistency": "contract_consistency",
            "price_stability_score": "price_stability_score",
            "quantity_volatility": "quantity_volatility",
            "additional_expenses_ratio": "additional_expenses_ratio",
            "avg_quantity_per_contract": "avg_quantity_per_contract",
            "revenue_per_project": "revenue_per_project",
            "avg_contract_size_rank": "avg_contract_size_rank",
            "total_volume_rank": "total_volume_rank",
            "single_client_dependency": "single_client_dependency",
            "seasonal_variance": "seasonal_variance",
        }
        return rename_mapping
        
    def find_optimal_clusters(self, features, max_clusters=10):
        """ะะพะธัะบ ะพะฟัะธะผะฐะปัะฝะพะณะพ ะบะพะปะธัะตััะฒะฐ ะบะปะฐััะตัะพะฒ ะผะตัะพะดะพะผ ะปะพะบัั ะธ ัะธะปัััะฐ"""
        inertias = []
        silhouette_scores = []
        K_range = range(2, max_clusters + 1)

        for k in K_range:
            kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
            kmeans.fit(features)
            inertias.append(kmeans.inertia_)
            silhouette_scores.append(silhouette_score(features, kmeans.labels_))

        # ะะธะทัะฐะปะธะทะฐัะธั
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))

        # ะัะฐัะธะบ ะปะพะบัั
        ax1.plot(K_range, inertias, "bo-")
        ax1.set_xlabel("ะะพะปะธัะตััะฒะพ ะบะปะฐััะตัะพะฒ")
        ax1.set_ylabel("ะะฝะตััะธั")
        ax1.set_title("ะะตัะพะด ะปะพะบัั")
        ax1.grid(True)

        # ะัะฐัะธะบ ัะธะปัััะฐ
        ax2.plot(K_range, silhouette_scores, "ro-")
        ax2.set_xlabel("ะะพะปะธัะตััะฒะพ ะบะปะฐััะตัะพะฒ")
        ax2.set_ylabel("ะกะธะปััั-ะบะพัััะธัะธะตะฝั")
        ax2.set_title("ะะฝะฐะปะธะท ัะธะปัััะฐ")
        ax2.grid(True)

        plt.tight_layout()
        plt.show()

        # ะะตะบะพะผะตะฝะดัะตะผ ะพะฟัะธะผะฐะปัะฝะพะต k
        optimal_k = K_range[np.argmax(silhouette_scores)]
        print(f"ะะตะบะพะผะตะฝะดัะตะผะพะต ะบะพะปะธัะตััะฒะพ ะบะปะฐััะตัะพะฒ: {optimal_k}")
        print(f"ะกะธะปััั-ะบะพัััะธัะธะตะฝั: {max(silhouette_scores):.3f}")

        return optimal_k

    def cluster_suppliers(self, n_clusters=None):
        """ะะปะฐััะตัะธะทะฐัะธั ะฟะพััะฐะฒัะธะบะพะฒ ั ัะฐััะธัะตะฝะฝัะผ ะฝะฐะฑะพัะพะผ ะฟัะธะทะฝะฐะบะพะฒ"""
        # ะะพะดะณะพัะพะฒะบะฐ ะดะฐะฝะฝัั
        supplier_stats = self.prepare_enhanced_supplier_features() # ะฒ ััะพะน ััะฝะบัะธะธ ะฒัะต ะธัะฟัะฐะฒะปะตะฝะพ

        # ะัะฑะธัะฐะตะผ ะฟัะธะทะฝะฐะบะธ ะดะปั ะบะปะฐััะตัะธะทะฐัะธะธ
        rename_mapping = self.get_enhanced_feature_columns()

        # ะะตัะตะธะผะตะฝัะตะผ ััะพะปะฑัั ะดะฐัะฐััะตะนะผะฐ
        
        supplier_stats.rename(columns=rename_mapping, inplace=True)
        print(f"๐ ะัะฟะพะปัะทัะตััั {len(supplier_stats.columns)} ะฟัะธะทะฝะฐะบะพะฒ")
        
        # ะฃะดะฐะปัะตะผ ะฒัะฑัะพัั (ะฟะพััะฐะฒัะธะบะพะฒ ั ัะบัััะตะผะฐะปัะฝัะผะธ ะทะฝะฐัะตะฝะธัะผะธ)
        # ะะฐัะพะดะธะผ ะฟะพััะฐะฒัะธะบะพะฒ, ะบะพัะพััะต ัะธะปัะฝะพ ะพัะปะธัะฐัััั ะฟะพ ะพะฑัะตะผั
        volume_q99 = supplier_stats["total_volume"].quantile(0.99)
        outliers_mask = supplier_stats["total_volume"] > volume_q99
        
        if outliers_mask.sum() > 0:
            print(f"โ๏ธ ะะฐะนะดะตะฝะพ {outliers_mask.sum()} ะฒัะฑัะพัะพะฒ (ััะฟะตั-ะฟะพััะฐะฒัะธะบะพะฒ):")
            outliers = supplier_stats[outliers_mask]["counterparty_name"].tolist()
            for outlier in outliers:
                volume = supplier_stats[
                    outliers_mask & (supplier_stats["counterparty_name"] == outlier)
                ]["total_volume"].iloc[0]
                print(f"   - {outlier}: {volume:,.0f} EUR")
        
        # ะะพะปััะฐะตะผ ะดะฐะฝะฝัะต ะฑะตะท ะฒัะฑัะพัะพะฒ ะดะปั ะดะฐะปัะฝะตะนัะตะน ะบะปะฐััะตัะธะทะฐัะธะธ
        normal_suppliers = supplier_stats[~outliers_mask].copy()
        
        # ะััะธะปััััะตะผ ัะพะปัะบะพ ัะธัะปะพะฒัะต ะฟัะธะทะฝะฐะบะธ
        numerical_features = normal_suppliers.select_dtypes(include=['number']).columns.tolist()
        
        # ะะฟัะตะดะตะปัะตะผ ัะฟะธัะพะบ ะฟัะธะทะฝะฐะบะพะฒ ะดะปั ะบะปะฐััะตัะธะทะฐัะธะธ
        features_for_clustering = [col for col in numerical_features if col not in ['counterparty_name']]
        
        print(f"๐ฏ ะะปะฐััะตัะธะทัะตะผ {len(normal_suppliers)} ะพะฑััะฝัั ะฟะพััะฐะฒัะธะบะพะฒ")
        
        normal_features_to_scale = normal_suppliers[features_for_clustering]

        # ะกัะฐะฝะดะฐััะธะทะฐัะธั ัะพะปัะบะพ ะฝะพัะผะฐะปัะฝัั ะดะฐะฝะฝัั (ะฑะตะท ะฒัะฑัะพัะพะฒ)
        normal_features_scaled = self.scaler.fit_transform(normal_features_to_scale)

        # ะะพะธัะบ ะพะฟัะธะผะฐะปัะฝะพะณะพ ะบะพะปะธัะตััะฒะฐ ะบะปะฐััะตัะพะฒ (ะฝะพ ะฝะต ะผะตะฝะตะต 3)
        if n_clusters is None:
            optimal_k = self.find_optimal_clusters(normal_features_scaled, max_clusters=8)
            n_clusters = max(optimal_k, 3) # ะผะธะฝะธะผัะผ 3 ะบะปะฐััะตัะฐ
        
        print(f"๐ฏ ะัะฟะพะปัะทัะตะผ {n_clusters} ะบะปะฐััะตัะพะฒ")

        # ะะปะฐััะตัะธะทะฐัะธั ะพัะฝะพะฒะฝะพะน ะผะฐััั
        kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
        normal_suppliers["cluster"] = kmeans.fit_predict(normal_features_scaled)
        
        # ะะพะฑะฐะฒะปัะตะผ ะฒัะฑัะพัั ะบะฐะบ ะพัะดะตะปัะฝัะต ะบะปะฐััะตัั
        if outliers_mask.sum() > 0:
            outlier_suppliers = supplier_stats[outliers_mask].copy()
            # ะัะธัะฒะฐะธะฒะฐะตะผ ะบะฐะถะดะพะผั ะฒัะฑัะพัั ัะฒะพะน ะบะปะฐััะตั
            outlier_suppliers["cluster"] = range(
                n_clusters, n_clusters + len(outlier_suppliers)
            )
            # ะะฑัะตะดะธะฝัะตะผ ะฒัะต ะดะฐะฝะฝัะต
            supplier_stats_final = pd.concat(
                [normal_suppliers, outlier_suppliers], ignore_index=True
            )
        else:
            supplier_stats_final = normal_suppliers

        self.clusters = supplier_stats_final
        self.cluster_centers = kmeans.cluster_centers_
        self.feature_columns = features_for_clustering

        return supplier_stats_final

    def analyze_enhanced_clusters(self):
        """ะะฐััะธัะตะฝะฝัะน ะฐะฝะฐะปะธะท ัะฐัะฐะบัะตัะธััะธะบ ะบะปะฐััะตัะพะฒ"""
        if self.clusters is None:
            print("ะกะฝะฐัะฐะปะฐ ะฒัะฟะพะปะฝะธัะต ะบะปะฐััะตัะธะทะฐัะธั!")
            return

        # ะะปััะตะฒัะต ะฟะพะบะฐะทะฐัะตะปะธ ะดะปั ะฐะฝะฐะปะธะทะฐ
        key_metrics = [
            "total_volume",
            "avg_contract_value",
            "contracts_count",
            "price_volatility",
            "years_active",
            "projects_count",
            "diversification_index",
            "delivery_efficiency",
            "contract_consistency",
            "specialization_ratio",
        ]

        available_metrics = [col for col in key_metrics if col in self.clusters.columns and col != 'counterparty_name']

        # ะกัะฐัะธััะธะบะฐ ะฟะพ ะบะปะฐััะตัะฐะผ
        cluster_summary = (
            self.clusters.groupby("cluster")
            .agg(
                {
                    "counterparty_name": "count",
                    **{col: "mean" for col in available_metrics},
                }
            )
            .round(3)
        )

        cluster_summary.columns = ["ะะพะปะธัะตััะฒะพ"] + [
            col.replace("_", " ").title() for col in available_metrics
        ]

        print("=== ะะะกะจะะะะะะะฏ ะฅะะะะะขะะะะกะขะะะ ะะะะกะขะะะะ ===")
        print(cluster_summary)

        # ะะตัะฐะปัะฝะฐั ะธะฝัะตัะฟัะตัะฐัะธั ะบะปะฐััะตัะพะฒ
        print("\n=== ะะะขะะะะะะขะะฆะะฏ ะะะะกะขะะะะ ===")
        for cluster_id in sorted(self.clusters["cluster"].unique()):
            cluster_data = self.clusters[self.clusters["cluster"] == cluster_id]
            # cluster_data - ะฒัะต ะดะฐะฝะฝัะต ะฟะพ ะบะปะฐััะตัั โ cluster_id (ะฒ ะฑัะดััะตะผ ะฒัะฝะตััะธ ะฒ Excel)
            # ะะฐััะตั ัะฐัะฐะบัะตัะธััะธะบ ะบะปะฐััะตัะฐ
            avg_volume = cluster_data["total_volume"].mean()
            avg_volatility = (
                cluster_data["price_volatility"].mean()
                if "price_volatility" in cluster_data.columns
                else 0
            )
            avg_projects = cluster_data["projects_count"].mean()
            avg_contracts = cluster_data["contracts_count"].mean()
            avg_years = cluster_data["years_active"].mean()

            # ะะฟัะตะดะตะปะตะฝะธะต ัะธะฟะฐ ะฟะพััะฐะฒัะธะบะฐ
            if avg_volume > self.clusters["total_volume"].quantile(0.8):
                if avg_volatility < 0.2 and avg_years > 2:
                    category = "๐ PREMIUM (ะบััะฟะฝัะต, ััะฐะฑะธะปัะฝัะต, ะพะฟััะฝัะต)"
                else:
                    category = "โก ะะะฃะะะซะ (ะฒััะพะบะธะน ะพะฑัะตะผ, ะฝะพ ะฝะตััะฐะฑะธะปัะฝัะต)"
            elif avg_contracts > self.clusters["contracts_count"].quantile(0.7):
                if avg_projects > 3:
                    category = "๐ ะะะขะะะะซะ ะฃะะะะะะกะะะซ (ัะฐัััะต ะทะฐะบะฐะทั, ะผะฝะพะณะพ ะฟัะพะตะบัะพะฒ)"
                else:
                    category = (
                        "๐ ะะะขะะะะซะ ะกะะะฆะะะะะกะขะซ (ัะฐัััะต ะทะฐะบะฐะทั, ัะทะบะฐั ัะฟะตัะธะฐะปะธะทะฐัะธั)"
                    )
            elif avg_years < 1:
                category = "๐ ะะะะซะ (ะฝะตะดะฐะฒะฝะพ ะฝะฐัะฐะปะธ ัะฐะฑะพัะฐัั)"
            elif avg_projects == 1:
                category = "๐ฏ ะฃะะะะกะะะฆะะะะะะะะะะะะะซะ (ัะฐะฑะพัะฐัั ะฒ ะพะดะฝะพะผ ะฟัะพะตะบัะต)"
            else:
                category = "๐ ะะะะะะ (ะฝะตัะตะณัะปััะฝัะต ะฟะพััะฐะฒัะธะบะธ)"

            print(f"\nะะปะฐััะตั {cluster_id}: {category}")
            print(f"  ะะพััะฐะฒัะธะบะพะฒ: {len(cluster_data)}")
            print(f"  ะกัะตะดะฝะธะน ะพะฑัะตะผ: {avg_volume:,.0f} EUR")
            print(f"  ะะพะปะฐัะธะปัะฝะพััั ัะตะฝ: {avg_volatility:.3f}")
            print(f"  ะกัะตะดะฝะตะต ะบะพะป-ะฒะพ ะฟัะพะตะบัะพะฒ: {avg_projects:.1f}")
            print(f"  ะกัะตะดะฝะตะต ะบะพะป-ะฒะพ ะบะพะฝััะฐะบัะพะฒ: {avg_contracts:.1f}")
            print(f"  ะกัะตะดะฝะธะน ะพะฟัั ัะฐะฑะพัั: {avg_years:.1f} ะปะตั")

            # ะะพะบะฐะทัะฒะฐะตะผ ัะพะฟ- ะฟะพััะฐะฒัะธะบะพะฒ ะฒ ะบะปะฐััะตัะต
            top_suppliers = cluster_data.nlargest(5, "total_volume")[
                "counterparty_name"
            ].tolist()
            print(
                f"  ะขะพะฟ ะฟะพััะฐะฒัะธะบะธ: {', '.join(top_suppliers[:4])}{'...' if len(top_suppliers) > 4 else ''}"
            )

        return cluster_summary
    
    def visualize_enhanced_clusters(self, output_folder):
        import os
        import pandas as pd
        import numpy as np
        from sklearn.decomposition import PCA
        import matplotlib.pyplot as plt
        """
        ะะฐััะธัะตะฝะฝะฐั ะฒะธะทัะฐะปะธะทะฐัะธั ะบะปะฐััะตัะพะฒ.
        ะกะพััะฐะฝัะตั ะณัะฐัะธะบะธ ะฒ ัะบะฐะทะฐะฝะฝัั ะฟะฐะฟะบั.
        """
        if self.clusters is None:
            print("ะกะฝะฐัะฐะปะฐ ะฒัะฟะพะปะฝะธัะต ะบะปะฐััะตัะธะทะฐัะธั!")
            return
    
        # 1. ะกะพะทะดะฐะฝะธะต ะฟะฐะฟะบะธ, ะตัะปะธ ะพะฝะฐ ะฝะต ัััะตััะฒัะตั
        if not os.path.exists(output_folder):
            os.makedirs(output_folder)
            print(f"โ ะกะพะทะดะฐะฝะฐ ะฟะฐะฟะบะฐ ะดะปั ัะตะทัะปััะฐัะพะฒ: {output_folder}")
    
        # ะะพะดะณะพัะพะฒะบะฐ ะดะฐะฝะฝัั ะดะปั PCA
        features = self.clusters[self.feature_columns]
        features_scaled = self.scaler.transform(features)
    
        # PCA ะดะปั ะฒะธะทัะฐะปะธะทะฐัะธะธ
        pca = PCA(n_components=2)
        features_pca = pca.fit_transform(features_scaled)
    
        # ะกะพะทะดะฐะตะผ DataFrame ะดะปั ัะดะพะฑััะฒะฐ
        plot_data = pd.DataFrame(
            {
                "PC1": features_pca[:, 0],
                "PC2": features_pca[:, 1],
                "cluster": self.clusters["cluster"],
                "supplier": self.clusters["counterparty_name"],
                "total_volume": self.clusters["total_volume"],
                "contracts_count": self.clusters["contracts_count"],
                "diversification": self.clusters.get("diversification_index", 1),
            }
        )
    
        # ะกะพะทะดะฐะตะผ ะบะพะผะฟะปะตะบัะฝัั ะฒะธะทัะฐะปะธะทะฐัะธั
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
    
        # 1. ะัะฝะพะฒะฝะพะน PCA scatter plot
        scatter1 = ax1.scatter(
            plot_data["PC1"],
            plot_data["PC2"],
            c=plot_data["cluster"],
            s=np.sqrt(plot_data["total_volume"]) / 50,
            alpha=0.7,
            cmap="tab10",
        )
        ax1.set_xlabel(f"PC1 ({pca.explained_variance_ratio_[0]:.1%} ะดะธัะฟะตััะธะธ)")
        ax1.set_ylabel(f"PC2 ({pca.explained_variance_ratio_[1]:.1%} ะดะธัะฟะตััะธะธ)")
        ax1.set_title("PCA ะบะปะฐััะตัะพะฒ (ัะฐะทะผะตั = ะพะฑัะตะผ ะทะฐะบัะฟะพะบ)")
        ax1.grid(True, alpha=0.3)
        plt.colorbar(scatter1, ax=ax1, label="ะะปะฐััะตั")
    
        # 2. ะะฑัะตะผ vs ะะพะปะธัะตััะฒะพ ะบะพะฝััะฐะบัะพะฒ
        scatter2 = ax2.scatter(
            self.clusters["total_volume"],
            self.clusters["contracts_count"],
            c=self.clusters["cluster"],
            alpha=0.7,
            cmap="tab10",
        )
        ax2.set_xlabel("ะะฑัะธะน ะพะฑัะตะผ (EUR)")
        ax2.set_ylabel("ะะพะปะธัะตััะฒะพ ะบะพะฝััะฐะบัะพะฒ")
        ax2.set_title("ะะฑัะตะผ vs ะะบัะธะฒะฝะพััั")
        ax2.set_xscale("log")
        ax2.grid(True, alpha=0.3)
    
        # 3. ะะพะปะฐัะธะปัะฝะพััั vs ะะฐะทะผะตั
        if "price_volatility" in self.clusters.columns:
            scatter3 = ax3.scatter(
                self.clusters["price_volatility"],
                self.clusters["avg_contract_value"],
                c=self.clusters["cluster"],
                alpha=0.7,
                cmap="tab10",
            )
            ax3.set_xlabel("ะะพะปะฐัะธะปัะฝะพััั ัะตะฝ")
            ax3.set_ylabel("ะกัะตะดะฝัั ััะพะธะผะพััั ะบะพะฝััะฐะบัะฐ (EUR)")
            ax3.set_title("ะกัะฐะฑะธะปัะฝะพััั vs ะะฐะทะผะตั ะบะพะฝััะฐะบัะฐ")
            ax3.set_yscale("log")
            ax3.grid(True, alpha=0.3)
    
        # 4. ะะธะฒะตััะธัะธะบะฐัะธั vs ะกะฟะตัะธะฐะปะธะทะฐัะธั
        if (
            "diversification_index" in self.clusters.columns
            and "specialization_ratio" in self.clusters.columns
        ):
            scatter4 = ax4.scatter(
                self.clusters["diversification_index"],
                self.clusters["specialization_ratio"],
                c=self.clusters["cluster"],
                alpha=0.7,
                cmap="tab10",
            )
            ax4.set_xlabel("ะะฝะดะตะบั ะดะธะฒะตััะธัะธะบะฐัะธะธ")
            ax4.set_ylabel("ะะพัััะธัะธะตะฝั ัะฟะตัะธะฐะปะธะทะฐัะธะธ")
            ax4.set_title("ะะธะฒะตััะธัะธะบะฐัะธั vs ะกะฟะตัะธะฐะปะธะทะฐัะธั")
            ax4.grid(True, alpha=0.3)
    
        plt.tight_layout()
    
        # 2. ะกะพะทะดะฐะฝะธะต ะฟะพะปะฝะพะณะพ ะฟััะธ ะธ ัะพััะฐะฝะตะฝะธะต ะณัะฐัะธะบะฐ
        full_path_visualization = os.path.join(output_folder, "cluster_visualization.png")
        plt.savefig(full_path_visualization)
    
        plt.show()
    
        print(f"โ ะัะฐัะธะบะธ ะฒะธะทัะฐะปะธะทะฐัะธะธ ัะพััะฐะฝะตะฝั ะฒ: {full_path_visualization}")
        print(f"PCA ะพะฑัััะฝัะตั {pca.explained_variance_ratio_.sum():.1%} ะดะธัะฟะตััะธะธ")
        print(f"ะัะฟะพะปัะทะพะฒะฐะฝะพ {len(self.feature_columns)} ะฟัะธะทะฝะฐะบะพะฒ ะดะปั ะบะปะฐััะตัะธะทะฐัะธะธ")

    def get_enhanced_recommendations(self):
        """ะะฐััะธัะตะฝะฝัะต ัะตะบะพะผะตะฝะดะฐัะธะธ ะฟะพ ัะฐะฑะพัะต ั ะบะปะฐััะตัะฐะผะธ"""
        if self.clusters is None:
            print("ะกะฝะฐัะฐะปะฐ ะฒัะฟะพะปะฝะธัะต ะบะปะฐััะตัะธะทะฐัะธั!")
            return

        recommendations = {
            "๐ PREMIUM": [
                "ะะฐะทะฒะธะฒะฐัั ะดะพะปะณะพััะพัะฝะพะต ัััะฐัะตะณะธัะตัะบะพะต ะฟะฐััะฝะตัััะฒะพ",
                "ะัะตะดะพััะฐะฒะปััั ะฟัะธะพัะธัะตั ะฒ ะฝะพะฒัั ัะตะฝะดะตัะฐั",
                "ะะฐะบะปััะฐัั ัะฐะผะพัะฝัะต ัะพะณะปะฐัะตะฝะธั ะฝะฐ ะฒัะณะพะดะฝัั ััะปะพะฒะธัั",
                "ะะตะณัะปััะฝัะต ะฒัััะตัะธ ะดะปั ัััะฐัะตะณะธัะตัะบะพะณะพ ะฟะปะฐะฝะธัะพะฒะฐะฝะธั",
                "ะกะพะฒะผะตััะฝะฐั ัะฐะทัะฐะฑะพัะบะฐ ะธะฝะฝะพะฒะฐัะธะพะฝะฝัั ัะตัะตะฝะธะน",
            ],
            "โก ะะะฃะะะซะ": [
                "ะะฐะฑะพัะฐัั ะฝะฐะด ััะฐะฑะธะปะธะทะฐัะธะตะน ัะตะฝ",
                "ะะฐะบะปััะฐัั ะดะพะณะพะฒะพัั ั ัะธะบัะธัะพะฒะฐะฝะฝัะผะธ ัะตะฝะฐะผะธ",
                "ะฃัะธะปะตะฝะฝัะน ะบะพะฝััะพะปั ะบะฐัะตััะฒะฐ",
                "ะะธะฒะตััะธัะธะบะฐัะธั ัะธัะบะพะฒ ัะตัะตะท ะดััะณะธั ะฟะพััะฐะฒัะธะบะพะฒ",
                "ะะตะณัะปััะฝัะน ะผะพะฝะธัะพัะธะฝะณ ัะธะฝะฐะฝัะพะฒะพะณะพ ัะพััะพัะฝะธั",
            ],
            "๐ ะะะขะะะะซะ": [
                "ะะฒัะพะผะฐัะธะทะธัะพะฒะฐัั ะฟัะพัะตััั ะทะฐะบะฐะทะฐ",
                "ะะฝะตะดัะธัั EDI-ัะธััะตะผั",
                "ะะฟัะธะผะธะทะธัะพะฒะฐัั ะปะพะณะธััะธะบั",
                "ะกะพะทะดะฐัั ะบะฐัะฐะปะพะณะธ ััะฐะฝะดะฐััะฝัั ะฟะพะทะธัะธะน",
                "ะฃะฟัะพััะธัั ะฟัะพัะตะดััั ัะพะณะปะฐัะพะฒะฐะฝะธั",
            ],
            "๐ฏ ะกะะะฆะะะะะะะะะะะะะซะ": [
                "ะฃะณะปัะฑะปััั ัะบัะฟะตััะธะทั ะฒ ะธั ะพะฑะปะฐััะธ",
                "ะัะธะฒะปะตะบะฐัั ะบ ะบะพะฝััะปััะฐัะธัะผ ะฟะพ ัะตัะฝะธัะตัะบะธะผ ัะตัะตะฝะธัะผ",
                "ะะฐะทะฒะธะฒะฐัั ัะบัะบะปัะทะธะฒะฝัะต ะฟะฐััะฝะตัััะฒะฐ",
                "ะกะพะฒะผะตััะฝะพะต ััะฐััะธะต ะฒ ะฒัััะฐะฒะบะฐั ะธ ะบะพะฝัะตัะตะฝัะธัั",
            ],
            "๐ ะะะะซะ": [
                "ะขัะฐัะตะปัะฝะฐั ะฟัะพะฒะตัะบะฐ ะฝะฐะดะตะถะฝะพััะธ",
                "ะะฐัะธะฝะฐัั ั ะฝะตะฑะพะปััะธั ะทะฐะบะฐะทะพะฒ",
                "ะะตะณัะปััะฝัะน ะผะพะฝะธัะพัะธะฝะณ ะฒัะฟะพะปะฝะตะฝะธั",
                "ะะฑััะตะฝะธะต ะบะพัะฟะพัะฐัะธะฒะฝัะผ ััะฐะฝะดะฐััะฐะผ",
                "ะะพััะตะฟะตะฝะฝะพะต ัะฒะตะปะธัะตะฝะธะต ะพะฑัะตะผะพะฒ ะฟัะธ ััะฟะตัะฝะพะน ัะฐะฑะพัะต",
            ],
            "๐ ะะะะะะ": [
                "ะะตัะตัะผะพััะตัั ะฝะตะพะฑัะพะดะธะผะพััั ัะพัััะดะฝะธัะตััะฒะฐ",
                "ะะฐะนัะธ ะฑะพะปะตะต ะฐะบัะธะฒะฝัั ะฟะพััะฐะฒัะธะบะพะฒ",
                "ะะธะฝะธะผะธะทะธัะพะฒะฐัั ะฐะดะผะธะฝะธัััะฐัะธะฒะฝัะต ะทะฐััะฐัั",
                "ะัะฟะพะปัะทะพะฒะฐัั ัะพะปัะบะพ ะดะปั ัะบัััะตะฝะฝัั ัะปััะฐะตะฒ",
                "ะะฐััะผะพััะตัั ะบะพะฝัะพะปะธะดะฐัะธั ั ะดััะณะธะผะธ ะฟะพััะฐะฒัะธะบะฐะผะธ",
            ],
        }

        print("=== ะะะกะจะะะะะะซะ ะะะะะะะะะะฆะะ ะะ ะะะะกะขะะะะ ===")
        for category, recs in recommendations.items():
            print(f"\n{category}:")
            for i, rec in enumerate(recs, 1):
                print(f"  {i}. {rec}")

    def save_results_to_excel(self, output_folder):
        """
        ะกะพััะฐะฝัะตั ัะตะทัะปััะฐัั ะบะปะฐััะตัะธะทะฐัะธะธ ะธ ัะฒะพะดะฝัั ััะฐัะธััะธะบั ะฒ Excel-ัะฐะนะปั.
        """
        if self.clusters is None:
            print("ะกะฝะฐัะฐะปะฐ ะฒัะฟะพะปะฝะธัะต ะบะปะฐััะตัะธะทะฐัะธั!")
            return

        # ะกะพะทะดะฐะฝะธะต ะฟะฐะฟะบะธ, ะตัะปะธ ะพะฝะฐ ะฝะต ัััะตััะฒัะตั
        import os
        if not os.path.exists(output_folder):
            os.makedirs(output_folder)
            print(f"โ ะกะพะทะดะฐะฝะฐ ะฟะฐะฟะบะฐ ะดะปั ัะตะทัะปััะฐัะพะฒ: {output_folder}")

        # 1. ะกะพััะฐะฝะตะฝะธะต ะฒัะตั ะดะฐะฝะฝัั ั ะบะปะฐััะตัะฐะผะธ
        full_path_clusters = os.path.join(output_folder, "supplier_clusters.xlsx")
        self.clusters.to_excel(full_path_clusters, index=False)
        print(f"โ ะะตะทัะปััะฐัั ะบะปะฐััะตัะธะทะฐัะธะธ ัะพััะฐะฝะตะฝั ะฒ: {full_path_clusters}")

        # 2. ะกะพััะฐะฝะตะฝะธะต ัะฒะพะดะฝะพะน ััะฐัะธััะธะบะธ ะฟะพ ะบะปะฐััะตัะฐะผ
        cluster_summary = self.analyze_enhanced_clusters()
        full_path_summary = os.path.join(output_folder, "cluster_summary.xlsx")
        cluster_summary.to_excel(full_path_summary)
        print(f"โ ะกะฒะพะดะฝะฐั ััะฐัะธััะธะบะฐ ะฟะพ ะบะปะฐััะตัะฐะผ ัะพััะฐะฝะตะฝะฐ ะฒ: {full_path_summary}")

        # 3. ะกะพััะฐะฝะตะฝะธะต ะฒัะฑัะพัะพะฒ ะฒ ะพัะดะตะปัะฝัะน ัะฐะนะป (ะตัะปะธ ะพะฝะธ ะตััั)
        outliers_mask = (self.clusters['cluster'] >= self.clusters['cluster'].nunique() -
                         len(self.clusters[self.clusters['cluster'].duplicated(keep=False) == False]))
        if outliers_mask.any():
            outliers_df = self.clusters[outliers_mask]
            full_path_outliers = os.path.join(output_folder, "outlier_suppliers.xlsx")
            outliers_df.to_excel(full_path_outliers, index=False)
            print(f"โ ะะฑะฝะฐััะถะตะฝะฝัะต ะฒัะฑัะพัั ัะพััะฐะฝะตะฝั ะฒ: {full_path_outliers}")
    
    def save_cluster_interpretation_to_excel(self, output_folder):
        """
        ะกะพััะฐะฝัะตั ะดะตัะฐะปัะฝัั ะธะฝัะตัะฟัะตัะฐัะธั ะบะปะฐััะตัะพะฒ ะฒ Excel.
        """
        if self.clusters is None:
            print("ะกะฝะฐัะฐะปะฐ ะฒัะฟะพะปะฝะธัะต ะบะปะฐััะตัะธะทะฐัะธั!")
            return
    
        import os
        import pandas as pd
    
        # ะกะพะทะดะฐะฝะธะต ะฟะฐะฟะบะธ, ะตัะปะธ ะพะฝะฐ ะฝะต ัััะตััะฒัะตั
        if not os.path.exists(output_folder):
            os.makedirs(output_folder)
            print(f"โ ะกะพะทะดะฐะฝะฐ ะฟะฐะฟะบะฐ ะดะปั ัะตะทัะปััะฐัะพะฒ: {output_folder}")
    
        # ะะพะดะณะพัะพะฒะบะฐ ะดะฐะฝะฝัั ะดะปั ัะพััะฐะฝะตะฝะธั
        interpretation_data = []
    
        # ะฆะธะบะป ะฟะพ ะบะปะฐััะตัะฐะผ
        for cluster_id in sorted(self.clusters["cluster"].unique()):
            cluster_data = self.clusters[self.clusters["cluster"] == cluster_id]
    
            # ะะฐััะตั ัะฐัะฐะบัะตัะธััะธะบ ะบะปะฐััะตัะฐ
            avg_volume = cluster_data["total_volume"].mean()
            avg_volatility = (
                cluster_data["price_volatility"].mean()
                if "price_volatility" in cluster_data.columns
                else 0
            )
            avg_projects = cluster_data["projects_count"].mean()
            avg_contracts = cluster_data["contracts_count"].mean()
            avg_years = cluster_data["years_active"].mean()
    
            # ะะฟัะตะดะตะปะตะฝะธะต ะบะฐัะตะณะพัะธะธ
            if avg_volume > self.clusters["total_volume"].quantile(0.8):
                if avg_volatility < 0.2 and avg_years > 2:
                    category = "๐ PREMIUM (ะบััะฟะฝัะต, ััะฐะฑะธะปัะฝัะต, ะพะฟััะฝัะต)"
                else:
                    category = "โก ะะะฃะะะซะ (ะฒััะพะบะธะน ะพะฑัะตะผ, ะฝะพ ะฝะตััะฐะฑะธะปัะฝัะต)"
            elif avg_contracts > self.clusters["contracts_count"].quantile(0.7):
                if avg_projects > 3:
                    category = "๐ ะะะขะะะะซะ ะฃะะะะะะกะะะซ (ัะฐัััะต ะทะฐะบะฐะทั, ะผะฝะพะณะพ ะฟัะพะตะบัะพะฒ)"
                else:
                    category = (
                        "๐ ะะะขะะะะซะ ะกะะะฆะะะะะกะขะซ (ัะฐัััะต ะทะฐะบะฐะทั, ัะทะบะฐั ัะฟะตัะธะฐะปะธะทะฐัะธั)"
                    )
            elif avg_years < 1:
                category = "๐ ะะะะซะ (ะฝะตะดะฐะฒะฝะพ ะฝะฐัะฐะปะธ ัะฐะฑะพัะฐัั)"
            elif avg_projects == 1:
                category = "๐ฏ ะฃะะะะกะะะฆะะะะะะะะะะะะะซะ (ัะฐะฑะพัะฐัั ะฒ ะพะดะฝะพะผ ะฟัะพะตะบัะต)"
            else:
                category = "๐ ะะะะะะ (ะฝะตัะตะณัะปััะฝัะต ะฟะพััะฐะฒัะธะบะธ)"
    
            # ะะพะปััะตะฝะธะต ัะพะฟ-ะฟะพััะฐะฒัะธะบะพะฒ
            top_suppliers = cluster_data.nlargest(5, "total_volume")[
                "counterparty_name"
            ].tolist()
    
            # ะะพะฑะฐะฒะปะตะฝะธะต ะดะฐะฝะฝัั ะฒ ัะฟะธัะพะบ
            interpretation_data.append(
                {
                    "Cluster ID": cluster_id,
                    "Category": category,
                    "Number of Suppliers": len(cluster_data),
                    "Average Volume (EUR)": round(avg_volume, 2),
                    "Price Volatility": round(avg_volatility, 3),
                    "Average Projects": round(avg_projects, 1),
                    "Average Contracts": round(avg_contracts, 1),
                    "Average Years Active": round(avg_years, 1),
                    "Top Suppliers": ", ".join(top_suppliers),
                }
            )
    
        # ะกะพะทะดะฐะฝะธะต DataFrame ะธะท ัะพะฑัะฐะฝะฝัั ะดะฐะฝะฝัั
        interpretation_df = pd.DataFrame(interpretation_data)
    
        # ะกะพััะฐะฝะตะฝะธะต ะฒ Excel
        full_path_interpretation = os.path.join(
            output_folder, "cluster_interpretation.xlsx"
        )
        interpretation_df.to_excel(full_path_interpretation, index=False)
    
        print(
            f"โ ะะตัะฐะปัะฝะฐั ะธะฝัะตัะฟัะตัะฐัะธั ะบะปะฐััะตัะพะฒ ัะพััะฐะฝะตะฝะฐ ะฒ: {full_path_interpretation}"
        )

def run_enhanced_supplier_clustering(df, output_folder=r'D:\Analysis-Results\Cluster_Analysis'):
    """
    ะะฐะฟััะบ ะฟะพะปะฝะพะณะพ ัะฐััะธัะตะฝะฝะพะณะพ ะฐะฝะฐะปะธะทะฐ ะบะปะฐััะตัะธะทะฐัะธะธ ะฟะพััะฐะฒัะธะบะพะฒ
    """
    print("๐ ะะพัััะฟะฝัะต ะบะพะปะพะฝะบะธ:", list(df.columns))

    analyzer = EnhancedSupplierClusterAnalyzer(df)

    # ะัะฟะพะปะฝัะตะผ ะบะปะฐััะตัะธะทะฐัะธั
    supplier_clusters = analyzer.cluster_suppliers()

    # ะะฝะฐะปะธะทะธััะตะผ ัะตะทัะปััะฐัั
    cluster_summary = analyzer.analyze_enhanced_clusters()

    # ะะธะทัะฐะปะธะทะธััะตะผ
    analyzer.visualize_enhanced_clusters(output_folder)

    # ะะพะปััะฐะตะผ ัะตะบะพะผะตะฝะดะฐัะธะธ
    analyzer.get_enhanced_recommendations()

    # ะกะพััะฐะฝัะตะผ ัะตะทัะปััะฐัั ะฒ Excel
    analyzer.save_results_to_excel(output_folder)
    analyzer.save_cluster_interpretation_to_excel(output_folder)

    return supplier_clusters, analyzer
