"""
product_matcher.py

–ú–æ–¥—É–ª—å –¥–ª—è –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–≥–æ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è —Ç–æ–≤–∞—Ä–æ–≤
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç –∞–ª–≥–æ—Ä–∏—Ç–º—ã –Ω–µ—á–µ—Ç–∫–æ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Å—Ç—Ä–æ–∫ (Fuzzy Matching)

–ê–≤—Ç–æ—Ä: –ö–æ–Ω—Ç—Ä–æ–ª—å–Ω–æ-—Ä–µ–≤–∏–∑–∏–æ–Ω–Ω—ã–π –¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç
–î–∞—Ç–∞: 2024
"""

import pandas as pd
import numpy as np
import re
from difflib import SequenceMatcher
from typing import Tuple, Dict, List, Any
from utils.product_matcher_improved import ProductMatcher


# ============================================================================
# –ê–õ–ì–û–†–ò–¢–ú–´ –ù–ï–ß–ï–¢–ö–û–ì–û –°–†–ê–í–ù–ï–ù–ò–Ø –°–¢–†–û–ö
# ============================================================================

def levenshtein_distance(s1: str, s2: str) -> int:
    """
    –†–∞—Å—Å—Ç–æ—è–Ω–∏–µ –õ–µ–≤–µ–Ω—à—Ç–µ–π–Ω–∞ - –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–ø–µ—Ä–∞—Ü–∏–π
    (–≤—Å—Ç–∞–≤–∫–∞, —É–¥–∞–ª–µ–Ω–∏–µ, –∑–∞–º–µ–Ω–∞) –¥–ª—è –ø—Ä–µ–≤—Ä–∞—â–µ–Ω–∏—è –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏ –≤ –¥—Ä—É–≥—É—é.

    Args:
        s1: –ø–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞
        s2: –≤—Ç–æ—Ä–∞—è —Å—Ç—Ä–æ–∫–∞

    Returns:
        int: —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ (0 = –∏–¥–µ–Ω—Ç–∏—á–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏)
    """
    if len(s1) < len(s2):
        return levenshtein_distance(s2, s1)

    if len(s2) == 0:
        return len(s1)

    previous_row = range(len(s2) + 1)
    for i, c1 in enumerate(s1):
        current_row = [i + 1]
        for j, c2 in enumerate(s2):
            insertions = previous_row[j + 1] + 1
            deletions = current_row[j] + 1
            substitutions = previous_row[j] + (c1 != c2)
            current_row.append(min(insertions, deletions, substitutions))
        previous_row = current_row

    return previous_row[-1]


def levenshtein_similarity(s1: str, s2: str) -> float:
    """
    –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ –õ–µ–≤–µ–Ω—à—Ç–µ–π–Ω–∞.

    Returns:
        float: –∑–Ω–∞—á–µ–Ω–∏–µ –æ—Ç 0 –¥–æ 1 (1 = –∏–¥–µ–Ω—Ç–∏—á–Ω—ã–µ)
    """
    distance = levenshtein_distance(s1, s2)
    max_len = max(len(s1), len(s2))
    if max_len == 0:
        return 1.0
    return 1.0 - (distance / max_len)


def jaro_similarity(s1: str, s2: str) -> float:
    """
    –°—Ö–æ–¥—Å—Ç–≤–æ –î–∂–∞—Ä–æ - —É—á–∏—Ç—ã–≤–∞–µ—Ç —Å–æ–≤–ø–∞–¥–∞—é—â–∏–µ —Å–∏–º–≤–æ–ª—ã –∏ —Ç—Ä–∞–Ω—Å–ø–æ–∑–∏—Ü–∏–∏.

    Returns:
        float: –∑–Ω–∞—á–µ–Ω–∏–µ –æ—Ç 0 –¥–æ 1
    """
    if s1 == s2:
        return 1.0

    len1, len2 = len(s1), len(s2)

    if len1 == 0 or len2 == 0:
        return 0.0

    match_distance = max(len1, len2) // 2 - 1
    if match_distance < 1:
        match_distance = 1

    s1_matches = [False] * len1
    s2_matches = [False] * len2

    matches = 0
    transpositions = 0

    for i in range(len1):
        start = max(0, i - match_distance)
        end = min(i + match_distance + 1, len2)

        for j in range(start, end):
            if s2_matches[j] or s1[i] != s2[j]:
                continue
            s1_matches[i] = True
            s2_matches[j] = True
            matches += 1
            break

    if matches == 0:
        return 0.0

    k = 0
    for i in range(len1):
        if not s1_matches[i]:
            continue
        while not s2_matches[k]:
            k += 1
        if s1[i] != s2[k]:
            transpositions += 1
        k += 1

    jaro = (matches / len1 + matches / len2 +
            (matches - transpositions / 2) / matches) / 3.0

    return jaro


def jaro_winkler_similarity(s1: str, s2: str, p: float = 0.1) -> float:
    """
    –°—Ö–æ–¥—Å—Ç–≤–æ –î–∂–∞—Ä–æ-–í–∏–Ω–∫–ª–µ—Ä–∞ - —É–ª—É—á—à–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –î–∂–∞—Ä–æ,
    –¥–∞–µ—Ç –±–æ–ª—å—à–∏–π –≤–µ—Å —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è–º –≤ –Ω–∞—á–∞–ª–µ —Å—Ç—Ä–æ–∫–∏.

    Args:
        s1: –ø–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞
        s2: –≤—Ç–æ—Ä–∞—è —Å—Ç—Ä–æ–∫–∞
        p: –≤–µ—Å –ø—Ä–µ—Ñ–∏–∫—Å–∞ (–æ–±—ã—á–Ω–æ 0.1)

    Returns:
        float: –∑–Ω–∞—á–µ–Ω–∏–µ –æ—Ç 0 –¥–æ 1
    """
    jaro_sim = jaro_similarity(s1, s2)

    prefix = 0
    for i in range(min(len(s1), len(s2), 4)):
        if s1[i] == s2[i]:
            prefix += 1
        else:
            break

    return jaro_sim + (prefix * p * (1 - jaro_sim))


def token_set_similarity(s1: str, s2: str) -> float:
    """
    –¢–æ–∫–µ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ - —Ä–∞–∑–±–∏–≤–∞–µ—Ç —Å—Ç—Ä–æ–∫–∏ –Ω–∞ —Å–ª–æ–≤–∞
    –∏ —Å—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç –Ω–∞–±–æ—Ä—ã —Ç–æ–∫–µ–Ω–æ–≤ (–∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –ñ–∞–∫–∫–∞—Ä–∞).

    Returns:
        float: –∑–Ω–∞—á–µ–Ω–∏–µ –æ—Ç 0 –¥–æ 1
    """
    tokens1 = set(s1.lower().split())
    tokens2 = set(s2.lower().split())

    if not tokens1 or not tokens2:
        return 0.0

    intersection = tokens1.intersection(tokens2)
    union = tokens1.union(tokens2)

    jaccard = len(intersection) / len(union) if union else 0.0

    return jaccard


def sequence_matcher_similarity(s1: str, s2: str) -> float:
    """
    –í—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π Python SequenceMatcher (–±—ã—Å—Ç—Ä—ã–π –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π).

    Returns:
        float: –∑–Ω–∞—á–µ–Ω–∏–µ –æ—Ç 0 –¥–æ 1
    """
    return SequenceMatcher(None, s1, s2).ratio()


# ============================================================================
# –ù–û–†–ú–ê–õ–ò–ó–ê–¶–ò–Ø –ò –ü–†–ï–î–û–ë–†–ê–ë–û–¢–ö–ê
# ============================================================================

def normalize_product_name(name: str) -> str:
    """
    –ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞ –¥–ª—è –ª—É—á—à–µ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è.

    Args:
        name: –∏—Å—Ö–æ–¥–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞

    Returns:
        str: –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ
    """
    name = str(name).lower()

    # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
    name = ' '.join(name.split())

    # –ó–∞–º–µ–Ω—è–µ–º —Ä–∞–∑–ª–∏—á–Ω—ã–µ –Ω–∞–ø–∏—Å–∞–Ω–∏—è
    replacements = {
        '√∏': 'o',
        '—Ñ': 'f',
        '‚àÖ': 'o',
        '—Ö': 'x',
        '√ó': 'x',
        '—ë': '–µ',
    }

    for old, new in replacements.items():
        name = name.replace(old, new)

    # –£–±–∏—Ä–∞–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã
    name = re.sub(r'\s+', ' ', name)

    return name.strip()


def extract_key_features(product_name: str) -> Dict[str, Any]:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–ª—é—á–µ–≤—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è —Ç–æ–≤–∞—Ä–∞.

    Args:
        product_name: –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞

    Returns:
        dict: —Å–ª–æ–≤–∞—Ä—å —Å –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã–º–∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞–º–∏
    """
    name_lower = str(product_name).lower()

    features = {
        'type': None,
        'diameter': None,
        'thickness': None,
        'number': None,
        'material': None,
        'gost': None
    }

    # –¢–∏–ø –∏–∑–¥–µ–ª–∏—è
    types = ['—Ç—Ä—É–±–∞', '—à–≤–µ–ª–ª–µ—Ä', '–¥–≤—É—Ç–∞–≤—Ä', '–∞—Ä–º–∞—Ç—É—Ä–∞', '—É–≥–æ–ª–æ–∫',
             '–ø—Ä–æ—Ñ–∏–ª—å', '–ª–∏—Å—Ç', '–ø–æ–ª–æ—Å–∞', '–∫—Ä—É–≥', '–ø—Ä–æ–≤–æ–ª–æ–∫–∞']
    for t in types:
        if t in name_lower:
            features['type'] = t
            break

    # –î–∏–∞–º–µ—Ç—Ä
    diameter_patterns = [r'[√∏—Ñ‚àÖd]\s*(\d+)', r'(\d+)\s*–º–º']
    for pattern in diameter_patterns:
        match = re.search(pattern, name_lower)
        if match:
            try:
                features['diameter'] = int(match.group(1))
                break
            except:
                pass

    # –ù–æ–º–µ—Ä (–¥–ª—è —à–≤–µ–ª–ª–µ—Ä–∞, –¥–≤—É—Ç–∞–≤—Ä–∞)
    if features['type'] in ['—à–≤–µ–ª–ª–µ—Ä', '–¥–≤—É—Ç–∞–≤—Ä']:
        number_pattern = r'[‚Ññ#]?\s*(\d+\.?\d*)[—É–ø–∞]?'
        match = re.search(number_pattern, name_lower)
        if match:
            try:
                features['number'] = float(match.group(1))
            except:
                pass

    # –ì–û–°–¢
    gost_match = re.search(r'–≥–æ—Å—Ç\s+[\d\-]+', name_lower)
    if gost_match:
        features['gost'] = gost_match.group(0)

    # –ú–∞—Ç–µ—Ä–∏–∞–ª
    materials = ['—Å—Ç3', '—Å—Ç20', '—Å245', '—Å255', '09–≥2—Å', '–æ—Ü–∏–Ω–∫']
    for mat in materials:
        if mat in name_lower:
            features['material'] = mat
            break

    return features


# ============================================================================
# –û–°–ù–û–í–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø –°–û–ü–û–°–¢–ê–í–õ–ï–ù–ò–Ø
# ============================================================================

def smart_product_match(
        product1: str,
        product2: str,
        method: str = 'combined'
) -> Tuple[float, Dict[str, Any]]:
    """
    –£–º–Ω–æ–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –¥–≤—É—Ö —Ç–æ–≤–∞—Ä–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –∞–ª–≥–æ—Ä–∏—Ç–º–∞.

    Args:
        product1: –Ω–∞–∑–≤–∞–Ω–∏–µ –ø–µ—Ä–≤–æ–≥–æ —Ç–æ–≤–∞—Ä–∞
        product2: –Ω–∞–∑–≤–∞–Ω–∏–µ –≤—Ç–æ—Ä–æ–≥–æ —Ç–æ–≤–∞—Ä–∞
        method: –º–µ—Ç–æ–¥ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è - 'levenshtein', 'jaro', 'jaro_winkler',
                'token', 'sequence', 'combined'

    Returns:
        tuple: (–æ—Ü–µ–Ω–∫–∞_—Å—Ö–æ–¥—Å—Ç–≤–∞, –¥–µ—Ç–∞–ª–∏)
            - –æ—Ü–µ–Ω–∫–∞_—Å—Ö–æ–¥—Å—Ç–≤–∞: float –æ—Ç 0 –¥–æ 1 (1 = –∏–¥–µ–Ω—Ç–∏—á–Ω—ã–µ)
            - –¥–µ—Ç–∞–ª–∏: dict —Å –ø–æ–¥—Ä–æ–±–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π

    Example:
        >>> score, details = smart_product_match(
        ...     "–®–≤–µ–ª–ª–µ—Ä 14–ü –ì–û–°–¢ 8240-97 –°245",
        ...     "–®–≤–µ–ª–ª–µ—Ä 14 –°245 –ì–û–°–¢ 8240-97"
        ... )
        >>> print(f"–°—Ö–æ–¥—Å—Ç–≤–æ: {score:.3f}")
        –°—Ö–æ–¥—Å—Ç–≤–æ: 0.923
    """
    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
    norm1 = normalize_product_name(product1)
    norm2 = normalize_product_name(product2)

    # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    feat1 = extract_key_features(product1)
    feat2 = extract_key_features(product2)

    # –ü—Ä–µ-—Ñ–∏–ª—å—Ç—Ä: –µ—Å–ª–∏ —Ç–∏–ø—ã —Ä–∞–∑–Ω—ã–µ - —Ç–æ—á–Ω–æ –Ω–µ —Å–æ–≤–ø–∞–¥–∞—é—Ç
    if feat1['type'] and feat2['type'] and feat1['type'] != feat2['type']:
        return 0.0, {"reason": "–†–∞–∑–Ω—ã–µ —Ç–∏–ø—ã –∏–∑–¥–µ–ª–∏–π"}

    # –í—ã–±–æ—Ä –º–µ—Ç–æ–¥–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
    scores = {}

    if method in ['levenshtein', 'combined']:
        scores['levenshtein'] = levenshtein_similarity(norm1, norm2)

    if method in ['jaro', 'combined']:
        scores['jaro'] = jaro_similarity(norm1, norm2)

    if method in ['jaro_winkler', 'combined']:
        scores['jaro_winkler'] = jaro_winkler_similarity(norm1, norm2)

    if method in ['token', 'combined']:
        scores['token'] = token_set_similarity(norm1, norm2)

    if method in ['sequence', 'combined']:
        scores['sequence'] = sequence_matcher_similarity(norm1, norm2)

    # –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ–¥—Ö–æ–¥
    if method == 'combined':
        weights = {
            'jaro_winkler': 0.3,
            'levenshtein': 0.25,
            'token': 0.25,
            'sequence': 0.2
        }
        final_score = sum(scores[k] * weights[k] for k in weights)
    else:
        final_score = scores[method]

    # –ë–æ–Ω—É—Å –∑–∞ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫
    bonus = 0.0
    bonus_details = []

    if feat1['diameter'] and feat2['diameter']:
        if feat1['diameter'] == feat2['diameter']:
            bonus += 0.1
            bonus_details.append("–¥–∏–∞–º–µ—Ç—Ä")

    if feat1['number'] and feat2['number']:
        if abs(feat1['number'] - feat2['number']) < 0.1:
            bonus += 0.1
            bonus_details.append("–Ω–æ–º–µ—Ä")

    if feat1['gost'] and feat2['gost']:
        if feat1['gost'] == feat2['gost']:
            bonus += 0.05
            bonus_details.append("–ì–û–°–¢")

    if feat1['material'] and feat2['material']:
        if feat1['material'] == feat2['material']:
            bonus += 0.05
            bonus_details.append("–º–∞—Ç–µ—Ä–∏–∞–ª")

    final_score = min(1.0, final_score + bonus)

    details = {
        'scores': scores,
        'bonus': bonus,
        'matching_features': bonus_details,
        'normalized1': norm1,
        'normalized2': norm2,
        'features1': feat1,
        'features2': feat2
    }

    return final_score, details


# ============================================================================
# –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò –î–õ–Ø –ü–ê–†–ê–õ–õ–ï–õ–ò–ó–ê–¶–ò–ò
# ============================================================================
from functools import lru_cache

@lru_cache(maxsize=50000)
def _extract_category_and_type_cached(name):
    """
    –ë—ã—Å—Ç—Ä–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ category –∏ type —Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º

    LRU –∫—ç—à —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è –ø–æ–≤—Ç–æ—Ä—è—é—â–∏—Ö—Å—è —Ç–æ–≤–∞—Ä–æ–≤.
    –ï—Å–ª–∏ —Ç–æ–≤–∞—Ä —É–∂–µ –≤—Å—Ç—Ä–µ—á–∞–ª—Å—è - —Ä–µ–∑—É–ª—å—Ç–∞—Ç –±–µ—Ä–µ—Ç—Å—è –∏–∑ –∫—ç—à–∞ –º–≥–Ω–æ–≤–µ–Ω–Ω–æ!

    maxsize=50000 - –∫—ç—à–∏—Ä—É–µ–º –¥–æ 50,000 —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤
    """
    feat = ProductMatcher.extract_key_features(name)
    return feat['category'], feat['type']


def _extract_category_and_type(name):
    """
    –û–±–µ—Ä—Ç–∫–∞ –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –≤–µ—Ä—Å–∏–∏ (–¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)
    """
    return _extract_category_and_type_cached(name)


# ============================================================================
# –§–£–ù–ö–¶–ò–Ø –î–õ–Ø –ü–û–ò–°–ö–ê –í –î–ê–¢–ê–§–†–ï–ô–ú–ï
# ============================================================================
def fast_find_comparable_products(df, threshold=0.85, parallel_threshold=10000):
    """
    –ë–´–°–¢–†–´–ô –ø–æ–∏—Å–∫ —Å–æ–ø–æ—Å—Ç–∞–≤–∏–º—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤ —Å –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–æ–π –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º

    Args:
        df: DataFrame —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏ ['–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ', '–ü–æ—Å—Ç–∞–≤—â–∏–∫', '–¶–µ–Ω–∞ –∑–∞ –µ–¥–∏–Ω–∏—Ü—É']
        threshold: –ø–æ—Ä–æ–≥ —Å—Ö–æ–∂–µ—Å—Ç–∏ (0.85 = 85%)
        parallel_threshold: –º–∏–Ω–∏–º—É–º —Ç–æ–≤–∞—Ä–æ–≤ –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–∞—Ü–∏–∏ (default: 10000)
                           –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ 0 –¥–ª—è –æ—Ç–∫–ª—é—á–µ–Ω–∏—è –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–∞—Ü–∏–∏
                           –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –º–µ–Ω—å—à–µ –¥–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è –Ω–∞ –º–∞–ª—ã—Ö –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–∞—Ö

    Returns:
        list: —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –Ω–∞–π–¥–µ–Ω–Ω—ã–º–∏ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è–º–∏
    """
    print("="*80)
    print("–ë–´–°–¢–†–´–ô –ü–û–ò–°–ö –°–û–ü–û–°–¢–ê–í–ò–ú–´–• –¢–û–í–ê–†–û–í")
    print("="*80)

    print("\n1. –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–π –∏ —Ç–∏–ø–æ–≤ —Ç–æ–≤–∞—Ä–æ–≤...")
    df = df.copy()

    # –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø: –ò–∑–≤–ª–µ–∫–∞–µ–º category –∏ type –∑–∞ –û–î–ò–ù –ø—Ä–æ—Ö–æ–¥
    # –ë—ã–ª–æ: 3 –ø—Ä–æ—Ö–æ–¥–∞ –ø–æ –≤—Å–µ–º —Ç–æ–≤–∞—Ä–∞–º
    # –°—Ç–∞–ª–æ: 1 –ø—Ä–æ—Ö–æ–¥
    print(f"   –û–±—Ä–∞–±–æ—Ç–∫–∞ {len(df)} —Ç–æ–≤–∞—Ä–æ–≤...")

    # ‚è±Ô∏è –ó–ê–ú–ï–† –í–†–ï–ú–ï–ù–ò - –ù–ê–ß–ê–õ–û
    import time
    start_time = time.time()

    # –ü—Ä–æ—Å—Ç–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –±–µ–∑ –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–∞—Ü–∏–∏ (–ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–∞—Ü–∏—è –∑–∞–º–µ–¥–ª—è–µ—Ç!)
    results = df['product_name'].apply(_extract_category_and_type)
    df['category'], df['product_type'] = zip(*results)

    # ‚è±Ô∏è –ó–ê–ú–ï–† –í–†–ï–ú–ï–ù–ò - –ö–û–ù–ï–¶
    elapsed_time = time.time() - start_time

    # üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫—ç—à–∞
    cache_info = _extract_category_and_type_cached.cache_info()
    cache_hit_rate = cache_info.hits / (cache_info.hits + cache_info.misses) * 100 if (cache_info.hits + cache_info.misses) > 0 else 0

    print(f"   ‚úÖ –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –¥–æ–±–∞–≤–ª–µ–Ω—ã –∑–∞ {elapsed_time:.2f} —Å–µ–∫—É–Ω–¥")
    print(f"   üìä –ö—ç—à: {cache_info.hits} –ø–æ–ø–∞–¥–∞–Ω–∏–π, {cache_info.misses} –ø—Ä–æ–º–∞—Ö–æ–≤ ({cache_hit_rate:.1f}% —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å)")
    print(f"   üíæ –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤: {cache_info.currsize}")

    if cache_hit_rate > 10:
        saved_time = (cache_info.hits * 0.015)  # ~15 –º—Å –Ω–∞ —Ç–æ–≤–∞—Ä
        print(f"   ‚ö° –ö—ç—à —Å—ç–∫–æ–Ω–æ–º–∏–ª ~{saved_time:.1f} —Å–µ–∫—É–Ω–¥!")

    # –°–æ–∑–¥–∞–µ–º –∫–ª—é—á –¥–ª—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ (–∫–∞—Ç–µ–≥–æ—Ä–∏—è + —Ç–∏–ø)
    df['key'] = df['category'].astype(str) + '_' + df['product_type'].astype(str)

    all_matches =[]

    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –∫–ª—é—á—É
    for key, group in df.groupby('key'):
        if len(group) < 2:
            continue

        category, product_type = key.split('_', 1)
        print(f"–û–±—Ä–∞–±–æ—Ç–∫–∞: {category} / {product_type}: {len(group)} —Ç–æ–≤–∞—Ä–æ–≤")

        # ‚ö° –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø: –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Å–ø–∏—Å–æ–∫ –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –∏—Ç–µ—Ä–∞—Ü–∏–∏
        rows = group.to_dict('records')  # –ë—ã—Å—Ç—Ä–µ–µ –≤ 100x —á–µ–º iterrows!
        n = len(rows)

        # –í–Ω—É—Ç—Ä–∏ –≥—Ä—É–ø–ø—ã —Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º –≤—Å–µ –ø–∞—Ä—ã
        for i in range(n):
            row1 = rows[i]
            for j in range(i + 1, n):  # –¢–æ–ª—å–∫–æ –ø–∞—Ä—ã –ø–æ—Å–ª–µ i
                row2 = rows[j]

                # –¢–æ–ª—å–∫–æ –µ—Å–ª–∏ —Ä–∞–∑–Ω—ã–µ –ø–æ—Å—Ç–∞–≤—â–∏–∫–∏
                if row1['counterparty_name'] != row2['counterparty_name']:
                    similarity = ProductMatcher.calculate_similarity(
                        row1['product_name'],
                        row2['product_name']
                    )

                    if similarity >= threshold:
                        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Ä–∞–∑–Ω–∏—Ü—É –≤ —Ü–µ–Ω–∞—Ö
                        price1 = row1['unit_price_eur']
                        price2 = row2['unit_price_eur']
                        price_diff = abs(price2 - price1)
                        price_diff_pct = (price_diff / price1 * 100) if price1 > 0 else 0

                        all_matches.append({
                            '–¢–æ–≤–∞—Ä_1': row1['product_name'],
                            '–ü–æ—Å—Ç–∞–≤—â–∏–∫_1': row1['counterparty_name'],
                            '–¶–µ–Ω–∞_1': price1,
                            '–¢–æ–≤–∞—Ä_2': row2['product_name'],
                            '–ü–æ—Å—Ç–∞–≤—â–∏–∫_2': row2['counterparty_name'],
                            '–¶–µ–Ω–∞_2': price2,
                            '–°—Ö–æ–∂–µ—Å—Ç—å': similarity,
                            '–†–∞–∑–Ω–∏—Ü–∞ –≤ —Ü–µ–Ω–µ': price_diff,
                            '–ü—Ä–æ—Ü–µ–Ω—Ç –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è': price_diff_pct,
                            '–ö–∞—Ç–µ–≥–æ—Ä–∏—è': category,
                            '–¢–∏–ø': product_type,
                            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
                            'product1': row1['product_name'],
                            'supplier1': row1['counterparty_name'],
                            'price1': price1,
                            'product2': row2['product_name'],
                            'supplier2': row2['counterparty_name'],
                            'price2': price2,
                            'similarity': similarity,
                            'price_diff': price_diff,
                            'price_diff_pct': price_diff_pct,
                            'category': category,
                            'type': product_type,
                            'cheaper_supplier': row1['counterparty_name'] if price1 < price2 else row2['counterparty_name'],
                            'expensive_supplier': row2['counterparty_name'] if price1 < price2 else row1['counterparty_name']
                        })

    return pd.DataFrame(all_matches)

# ============================================================================
# –§–£–ù–ö–¶–ò–Ø –î–õ–Ø –í–´–Ø–í–õ–ï–ù–ò–Ø –¶–ï–ù–û–í–´–• –†–ê–°–•–û–ñ–î–ï–ù–ò–ô
# ============================================================================

def find_price_discrepancies(
        df: pd.DataFrame,
        threshold: float = 0.85,
        method: str = 'combined',
        price_diff_threshold: float = 30.0
) -> pd.DataFrame:
    """
    –ù–∞—Ö–æ–¥–∏—Ç —Ç–æ–≤–∞—Ä—ã —Å –ø–æ—Ö–æ–∂–∏–º–∏ –Ω–∞–∑–≤–∞–Ω–∏—è–º–∏ –Ω–æ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ —Ä–∞–∑–ª–∏—á–∞—é—â–∏–º–∏—Å—è —Ü–µ–Ω–∞–º–∏.

    Args:
        df: DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏ –æ –∑–∞–∫—É–ø–∫–∞—Ö
        threshold: –ø–æ—Ä–æ–≥ —Å—Ö–æ–¥—Å—Ç–≤–∞ –Ω–∞–∑–≤–∞–Ω–∏–π (0-1)
        method: –º–µ—Ç–æ–¥ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        price_diff_threshold: –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Ä–∞–∑–Ω–∏—Ü–∞ –≤ —Ü–µ–Ω–∞—Ö –≤ % –¥–ª—è –æ—Ç—á–µ—Ç–∞

    Returns:
        DataFrame —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∞–Ω–∞–ª–∏–∑–∞

    Example:
        >>> discrepancies = find_price_discrepancies(df, price_diff_threshold=30)
        >>> print(discrepancies[['category', '–ü–æ—Å—Ç–∞–≤—â–∏–∫–æ–≤', '–†–∞–∑–Ω–∏—Ü–∞_%']])
    """
    comparable_groups = fast_find_comparable_products(df, threshold)

    # –§–∏–ª—å—Ç—Ä—É–µ–º –≥—Ä—É–ø–ø—ã —Å –±–æ–ª—å—à–æ–π —Ä–∞–∑–Ω–∏—Ü–µ–π –≤ —Ü–µ–Ω–∞—Ö
    high_diff_groups = [
        g for g in comparable_groups
        if g['price_diff_pct'] > price_diff_threshold
    ]

    print(f"\n–ê–ù–ê–õ–ò–ó –¶–ï–ù–û–í–´–• –†–ê–°–•–û–ñ–î–ï–ù–ò–ô")
    print("=" * 80)
    print(f"–í—Å–µ–≥–æ –≥—Ä—É–ø–ø —Å–æ–ø–æ—Å—Ç–∞–≤–∏–º—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤: {len(comparable_groups)}")
    print(f"–ì—Ä—É–ø–ø —Å —Ä–∞–∑–Ω–∏—Ü–µ–π —Ü–µ–Ω >{price_diff_threshold}%: {len(high_diff_groups)}")

    if high_diff_groups:
        print(f"\n‚ö†Ô∏è –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –†–ê–°–•–û–ñ–î–ï–ù–ò–Ø:")
        print("-" * 80)

        results = []
        for i, group_data in enumerate(high_diff_groups, 1):
            print(f"\n–ì—Ä—É–ø–ø–∞ {i}: {group_data['count']} –ø–æ—Å—Ç–∞–≤—â–∏–∫–æ–≤")
            print(f"–†–∞–∑–Ω–∏—Ü–∞ –≤ —Ü–µ–Ω–∞—Ö: {group_data['price_diff_pct']:.1f}%")

            for item in group_data['group']:
                print(f"  ‚Ä¢ {item['supplier']}")
                print(f"    {item['product'][:70]}")
                print(f"    –¶–µ–Ω–∞: {item['price']:,.0f} UZS")

                results.append({
                    '–ì—Ä—É–ø–ø–∞': i,
                    '–¢–æ–≤–∞—Ä': item['product'],
                    '–ü–æ—Å—Ç–∞–≤—â–∏–∫': item['supplier'],
                    '–¶–µ–Ω–∞_UZS': item['price'],
                    '–†–∞–∑–Ω–∏—Ü–∞_%': group_data['price_diff_pct']
                })

        return pd.DataFrame(results)
    else:
        print("\n‚úì –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏–π –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ")
        return pd.DataFrame()


# ============================================================================
# –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø –î–õ–Ø –ë–´–°–¢–†–û–ô –ü–†–û–í–ï–†–ö–ò
# ============================================================================

def quick_match(product1: str, product2: str, threshold: float = 0.85) -> bool:
    """
    –ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ - —Å–æ–≤–ø–∞–¥–∞—é—Ç –ª–∏ –¥–≤–∞ —Ç–æ–≤–∞—Ä–∞.

    Args:
        product1: –ø–µ—Ä–≤—ã–π —Ç–æ–≤–∞—Ä
        product2: –≤—Ç–æ—Ä–æ–π —Ç–æ–≤–∞—Ä
        threshold: –ø–æ—Ä–æ–≥ —Å—Ö–æ–¥—Å—Ç–≤–∞

    Returns:
        bool: True –µ—Å–ª–∏ —Ç–æ–≤–∞—Ä—ã —Å–æ–≤–ø–∞–¥–∞—é—Ç

    Example:
        >>> if quick_match("–®–≤–µ–ª–ª–µ—Ä 14–ü", "–®–≤–µ–ª–ª–µ—Ä 14"):
        ...     print("–°–æ–≤–ø–∞–¥–∞—é—Ç!")
    """
    score, _ = smart_product_match(product1, product2, method='combined')
    return score >= threshold


# ============================================================================
# –ò–ù–§–û–†–ú–ê–¶–ò–Ø –û –ú–û–î–£–õ–ï
# ============================================================================

def get_module_info():
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥—É–ª–µ."""
    info = """
    Product Matcher Module v1.0
    ============================

    –ú–æ–¥—É–ª—å –¥–ª—è –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–≥–æ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è —Ç–æ–≤–∞—Ä–æ–≤.

    –û—Å–Ω–æ–≤–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏:
    - smart_product_match(): —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –¥–≤—É—Ö —Ç–æ–≤–∞—Ä–æ–≤
    - find_comparable_products(): –ø–æ–∏—Å–∫ –≥—Ä—É–ø–ø –ø–æ—Ö–æ–∂–∏—Ö —Ç–æ–≤–∞—Ä–æ–≤
    - find_price_discrepancies(): –≤—ã—è–≤–ª–µ–Ω–∏–µ —Ü–µ–Ω–æ–≤—ã—Ö –∞–Ω–æ–º–∞–ª–∏–π
    - quick_match(): –±—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è

    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã:
    - Levenshtein Distance
    - Jaro Similarity
    - Jaro-Winkler Similarity
    - Token Set (Jaccard)
    - Sequence Matcher
    - Combined (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)

    –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
        from utils.product_matcher import smart_product_match

        score, details = smart_product_match(
            "–®–≤–µ–ª–ª–µ—Ä 14–ü –ì–û–°–¢ 8240-97",
            "–®–≤–µ–ª–ª–µ—Ä 14 –°245"
        )
        print(f"–°—Ö–æ–¥—Å—Ç–≤–æ: {score:.3f}")
    """
    return info


if __name__ == "__main__":
    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥—É–ª—è –ø—Ä–∏ –ø—Ä—è–º–æ–º –∑–∞–ø—É—Å–∫–µ
    print(get_module_info())

    # –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    print("\n" + "="*80)
    print("–ü–†–ò–ú–ï–†–´ –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Ø")
    print("="*80)

    test_pairs = [
        ("–®–≤–µ–ª–ª–µ—Ä 14–ü –ì–û–°–¢ 8240-97 –°245", "–®–≤–µ–ª–ª–µ—Ä 14 –°245 –ì–û–°–¢ 8240-97"),
        ("–¢—Ä—É–±–∞ —Å—Ç–∞–ª—å–Ω–∞—è √ò530—Ö10-–ö50", "–¢—Ä—É–±–∞ —Å—Ç–∞–ª—å–Ω–∞—è —Ñ530"),
        ("–ê—Ä–º–∞—Ç—É—Ä–∞ 12 –ê500", "–ê–†–ú–ê–¢–£–†–ê 12-–ê500"),
    ]

    for prod1, prod2 in test_pairs:
        score, details = smart_product_match(prod1, prod2)
        match = "‚úì –°–û–í–ü–ê–î–ê–Æ–¢" if score >= 0.85 else "‚úó –†–ê–ó–ù–´–ï"
        print(f"\n{prod1}")
        print(f"{prod2}")
        print(f"–°—Ö–æ–¥—Å—Ç–≤–æ: {score:.3f} {match}")
        if details['matching_features']:
            print(f"–°–æ–≤–ø–∞–¥–∞—é—Ç: {', '.join(details['matching_features'])}")