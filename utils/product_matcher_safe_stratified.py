"""
–ë–µ–∑–æ–ø–∞—Å–Ω—ã–π –ø–æ–∏—Å–∫ —Å–æ–ø–æ—Å—Ç–∞–≤–∏–º—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤ —Å–æ –°–¢–†–ê–¢–ò–§–ò–¶–ò–†–û–í–ê–ù–ù–û–ô –≤—ã–±–æ—Ä–∫–æ–π
–í–ï–†–°–ò–Ø 3.38 - STRATIFIED SAMPLING

–û—Å–Ω–æ–≤–Ω—ã–µ —É–ª—É—á—à–µ–Ω–∏—è:
- –°—Ç—Ä–∞—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞ –ø–æ —Ü–µ–Ω–æ–≤—ã–º –¥–∏–∞–ø–∞–∑–æ–Ω–∞–º
- –ù–∞—Ö–æ–¥–∏—Ç –ø–∞—Ä—ã –≤–æ –í–°–ï–• —Å–µ–≥–º–µ–Ω—Ç–∞—Ö (–¥–µ—à—ë–≤—ã–µ, —Å—Ä–µ–¥–Ω–∏–µ, –¥–æ—Ä–æ–≥–∏–µ)
- –ó–∞—â–∏—Ç–∞ –æ—Ç –ø–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∏—è –ø–∞–º—è—Ç–∏
- –ü—Ä–æ–ø—É—Å–∫ —Ç–æ–≤–∞—Ä–æ–≤ —Å category=None
"""

import pandas as pd
import numpy as np
from typing import List, Tuple
import time
from functools import lru_cache

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —É–ª—É—á—à–µ–Ω–Ω—ã–π ProductMatcher
try:
    from utils.product_matcher_improved import ProductMatcher
    print("‚úÖ –ú–æ–¥—É–ª—å product_matcher_improved –∑–∞–≥—Ä—É–∂–µ–Ω")
except ImportError:
    try:
        from utils.product_matcher_improved import ProductMatcher
        print("‚úÖ –ú–æ–¥—É–ª—å product_matcher_improved –∑–∞–≥—Ä—É–∂–µ–Ω (–∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –ø—É—Ç—å)")
    except ImportError:
        print("‚ùå –û–®–ò–ë–ö–ê: –ù–µ —É–¥–∞–ª–æ—Å—å –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å ProductMatcher")
        raise


# ==============================================================================
# –ù–ê–°–¢–†–û–ô–ö–ò –°–¢–†–ê–¢–ò–§–ò–¶–ò–†–û–í–ê–ù–ù–û–ô –í–´–ë–û–†–ö–ò
# ==============================================================================

MAX_GROUP_SIZE = 500  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –≥—Ä—É–ø–ø—ã –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏
STRATIFICATION_SETTINGS = {
    'low_price_threshold': 10,      # –ì—Ä–∞–Ω–∏—Ü–∞ –¥–µ—à—ë–≤—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤ (EUR)
    'high_price_threshold': 50,     # –ì—Ä–∞–Ω–∏—Ü–∞ –¥–æ—Ä–æ–≥–∏—Ö —Ç–æ–≤–∞—Ä–æ–≤ (EUR)
    'low_sample_size': 200,         # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–µ—à—ë–≤—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤
    'mid_sample_size': 200,         # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ä–µ–¥–Ω–∏—Ö —Ç–æ–≤–∞—Ä–æ–≤
    'high_sample_size': 100,        # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ—Ä–æ–≥–∏—Ö —Ç–æ–≤–∞—Ä–æ–≤
}


def stratified_sample_group(group: pd.DataFrame, max_size: int = MAX_GROUP_SIZE) -> pd.DataFrame:
    """
    –°—Ç—Ä–∞—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞ –∏–∑ –≥—Ä—É–ø–ø—ã —Ç–æ–≤–∞—Ä–æ–≤ –ø–æ —Ü–µ–Ω–æ–≤—ã–º –¥–∏–∞–ø–∞–∑–æ–Ω–∞–º.

    –†–∞–∑–¥–µ–ª—è–µ—Ç —Ç–æ–≤–∞—Ä—ã –Ω–∞ 3 —Å–µ–≥–º–µ–Ω—Ç–∞:
    - –î–µ—à—ë–≤—ã–µ (< 10 EUR)
    - –°—Ä–µ–¥–Ω–∏–µ (10-50 EUR)
    - –î–æ—Ä–æ–≥–∏–µ (> 50 EUR)

    –ë–µ—Ä—ë—Ç –ø—Ä–æ–ø–æ—Ä—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–∑ –∫–∞–∂–¥–æ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞.

    Args:
        group: DataFrame —Å —Ç–æ–≤–∞—Ä–∞–º–∏ –æ–¥–Ω–æ–π –≥—Ä—É–ø–ø—ã
        max_size: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏

    Returns:
        DataFrame —Å –≤—ã–±–æ—Ä–∫–æ–π —Ç–æ–≤–∞—Ä–æ–≤
    """
    group_size = len(group)

    # –ï—Å–ª–∏ –≥—Ä—É–ø–ø–∞ –º–∞–ª–µ–Ω—å–∫–∞—è, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å
    if group_size <= max_size:
        return group

    # –ü–æ–ª—É—á–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
    low_threshold = STRATIFICATION_SETTINGS['low_price_threshold']
    high_threshold = STRATIFICATION_SETTINGS['high_price_threshold']
    low_sample = STRATIFICATION_SETTINGS['low_sample_size']
    mid_sample = STRATIFICATION_SETTINGS['mid_sample_size']
    high_sample = STRATIFICATION_SETTINGS['high_sample_size']

    # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ —Ü–µ–Ω–æ–≤—ã–µ —Å–µ–≥–º–µ–Ω—Ç—ã
    low_price = group[group['unit_price_eur'] < low_threshold]
    mid_price = group[(group['unit_price_eur'] >= low_threshold) &
                      (group['unit_price_eur'] < high_threshold)]
    high_price = group[group['unit_price_eur'] >= high_threshold]

    # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä—ã —Å–µ–≥–º–µ–Ω—Ç–æ–≤
    n_low = len(low_price)
    n_mid = len(mid_price)
    n_high = len(high_price)

    # –ë–µ—Ä—ë–º –≤—ã–±–æ—Ä–∫—É –∏–∑ –∫–∞–∂–¥–æ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞
    samples = []

    if n_low > 0:
        sample_size_low = min(low_sample, n_low)
        samples.append(low_price.sample(n=sample_size_low, random_state=42))

    if n_mid > 0:
        sample_size_mid = min(mid_sample, n_mid)
        samples.append(mid_price.sample(n=sample_size_mid, random_state=42))

    if n_high > 0:
        sample_size_high = min(high_sample, n_high)
        samples.append(high_price.sample(n=sample_size_high, random_state=42))

    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—ã–±–æ—Ä–∫–∏
    if samples:
        stratified_group = pd.concat(samples, ignore_index=True)
    else:
        # –ï—Å–ª–∏ –ø–æ –∫–∞–∫–æ–π-—Ç–æ –ø—Ä–∏—á–∏–Ω–µ –Ω–µ—Ç –Ω–∏ –æ–¥–Ω–æ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞, –±–µ—Ä—ë–º —Å–ª—É—á–∞–π–Ω—É—é –≤—ã–±–æ—Ä–∫—É
        stratified_group = group.sample(n=min(max_size, group_size), random_state=42)

    return stratified_group


# –ö—ç—à –¥–ª—è extract_key_features (–¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è)
@lru_cache(maxsize=50000)
def cached_extract_key_features(product_name: str):
    """–ö—ç—à–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è extract_key_features"""
    return ProductMatcher.extract_key_features(product_name)


def find_comparable_products_safe(df: pd.DataFrame,
                                  similarity_threshold: float = 0.75) -> pd.DataFrame:
    """
    –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π –ø–æ–∏—Å–∫ —Å–æ–ø–æ—Å—Ç–∞–≤–∏–º—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤ —Å –∑–∞—â–∏—Ç–æ–π –æ—Ç –ø–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∏—è –ø–∞–º—è—Ç–∏
    –∏ —Å—Ç—Ä–∞—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–æ–π.

    Args:
        df: DataFrame —Å —Ç–æ–≤–∞—Ä–∞–º–∏ (–¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å 'product_name' –∏ 'unit_price_eur')
        similarity_threshold: –ü–æ—Ä–æ–≥ —Å—Ö–æ–∂–µ—Å—Ç–∏ –¥–ª—è —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è

    Returns:
        DataFrame —Å –ø–∞—Ä–∞–º–∏ —Å–æ–ø–æ—Å—Ç–∞–≤–∏–º—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤
    """
    print("\n" + "="*80)
    print("–ë–´–°–¢–†–´–ô –ü–û–ò–°–ö –°–û–ü–û–°–¢–ê–í–ò–ú–´–• –¢–û–í–ê–†–û–í (–°–¢–†–ê–¢–ò–§–ò–¶–ò–†–û–í–ê–ù–ù–ê–Ø –í–´–ë–û–†–ö–ê)")
    print("="*80)

    # 1. –î–æ–±–∞–≤–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏ —Ç–∏–ø—ã
    print("\n1. –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–π –∏ —Ç–∏–ø–æ–≤ —Ç–æ–≤–∞—Ä–æ–≤...")
    print(f"   –û–±—Ä–∞–±–æ—Ç–∫–∞ {len(df)} —Ç–æ–≤–∞—Ä–æ–≤...")

    start_time = time.time()

    # –ü—Ä–∏–º–µ–Ω—è–µ–º –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é
    features_list = []
    cache_hits = 0
    cache_misses = 0

    for product_name in df['product_name']:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –≤ –∫—ç—à–µ
        cache_info_before = cached_extract_key_features.cache_info()
        features = cached_extract_key_features(str(product_name))
        cache_info_after = cached_extract_key_features.cache_info()

        if cache_info_after.hits > cache_info_before.hits:
            cache_hits += 1
        else:
            cache_misses += 1

        features_list.append(features)

    # –°–æ–∑–¥–∞—ë–º –Ω–æ–≤—ã–µ —Å—Ç–æ–ª–±—Ü—ã
    df['category'] = [f['category'] for f in features_list]
    df['product_type'] = [f['type'] for f in features_list]

    elapsed = time.time() - start_time
    cache_info = cached_extract_key_features.cache_info()

    print(f"   ‚úÖ –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –¥–æ–±–∞–≤–ª–µ–Ω—ã –∑–∞ {elapsed:.2f} —Å–µ–∫—É–Ω–¥")
    print(f"   üìä –ö—ç—à: {cache_hits} –ø–æ–ø–∞–¥–∞–Ω–∏–π, {cache_misses} –ø—Ä–æ–º–∞—Ö–æ–≤ ({cache_hits/(cache_hits+cache_misses)*100:.1f}% —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å)")
    print(f"   üíæ –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤: {cache_info.currsize}")
    print(f"   ‚ö° –ö—ç—à —Å—ç–∫–æ–Ω–æ–º–∏–ª ~{cache_hits * 0.01:.1f} —Å–µ–∫—É–Ω–¥!")

    # 2. –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –∏ —Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º
    print("\n2. –ü–æ–∏—Å–∫ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π –≤–Ω—É—Ç—Ä–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–π (–°–¢–†–ê–¢–ò–§–ò–¶–ò–†–û–í–ê–ù–ù–ê–Ø –í–´–ë–û–†–ö–ê)...")

    results = []
    skipped_groups = 0
    skipped_items = 0
    total_groups = 0
    stratified_groups = 0

    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏ —Ç–∏–ø—É
    grouped = df.groupby(['category', 'product_type'])

    for (category, product_type), group in grouped:
        total_groups += 1
        group_size = len(group)

        # –ö–†–ò–¢–ò–ß–ù–û: –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –≥—Ä—É–ø–ø—ã —Å category=None
        if category == 'None' or category is None or pd.isna(category):
            print(f"   ‚ö†Ô∏è –ü–†–û–ü–£–°–ö: {category} / {product_type}: {group_size} —Ç–æ–≤–∞—Ä–æ–≤ (category=None)")
            skipped_groups += 1
            skipped_items += group_size
            continue

        # –ü—Ä–∏–º–µ–Ω—è–µ–º —Å—Ç—Ä–∞—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—É—é –≤—ã–±–æ—Ä–∫—É –¥–ª—è –±–æ–ª—å—à–∏—Ö –≥—Ä—É–ø–ø
        if group_size > MAX_GROUP_SIZE:
            print(f"   ‚ö†Ô∏è –ë–û–õ–¨–®–ê–Ø –ì–†–£–ü–ü–ê: {category} / {product_type}: {group_size} —Ç–æ–≤–∞—Ä–æ–≤")
            print(f"      –ü—Ä–∏–º–µ–Ω—è–µ–º –°–¢–†–ê–¢–ò–§–ò–¶–ò–†–û–í–ê–ù–ù–£–Æ –≤—ã–±–æ—Ä–∫—É...")
            print(f"      –î–µ—à—ë–≤—ã–µ (<{STRATIFICATION_SETTINGS['low_price_threshold']} EUR): –¥–æ {STRATIFICATION_SETTINGS['low_sample_size']} —à—Ç")
            print(f"      –°—Ä–µ–¥–Ω–∏–µ ({STRATIFICATION_SETTINGS['low_price_threshold']}-{STRATIFICATION_SETTINGS['high_price_threshold']} EUR): –¥–æ {STRATIFICATION_SETTINGS['mid_sample_size']} —à—Ç")
            print(f"      –î–æ—Ä–æ–≥–∏–µ (>{STRATIFICATION_SETTINGS['high_price_threshold']} EUR): –¥–æ {STRATIFICATION_SETTINGS['high_sample_size']} —à—Ç")

            group = stratified_sample_group(group, MAX_GROUP_SIZE)
            stratified_groups += 1

            print(f"      ‚úÖ –í—ã–±—Ä–∞–Ω–æ: {len(group)} —Ç–æ–≤–∞—Ä–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")

        print(f"   –û–±—Ä–∞–±–æ—Ç–∫–∞: {category} / {product_type}: {len(group)} —Ç–æ–≤–∞—Ä–æ–≤")

        # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –≤—Å–µ –ø–∞—Ä—ã –≤–Ω—É—Ç—Ä–∏ –≥—Ä—É–ø–ø—ã
        group_list = group.to_dict('records')

        for i in range(len(group_list)):
            for j in range(i + 1, len(group_list)):
                prod1 = group_list[i]
                prod2 = group_list[j]

                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ç–æ–≤–∞—Ä—ã –æ—Ç –æ–¥–Ω–æ–≥–æ –ø–æ—Å—Ç–∞–≤—â–∏–∫–∞
                if prod1['supplier_name'] == prod2['supplier_name']:
                    continue

                # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ö–æ–∂–µ—Å—Ç—å
                similarity = ProductMatcher.calculate_similarity(
                    prod1['product_name'],
                    prod2['product_name']
                )

                if similarity >= similarity_threshold:
                    results.append({
                        'product_name_1': prod1['product_name'],
                        'product_name_2': prod2['product_name'],
                        'supplier_1': prod1['supplier_name'],
                        'supplier_2': prod2['supplier_name'],
                        'price_1': prod1['unit_price_eur'],
                        'price_2': prod2['unit_price_eur'],
                        'category': category,
                        'product_type': product_type,
                        'similarity': similarity
                    })

    print(f"\n‚úÖ –ù–∞–π–¥–µ–Ω–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π: {len(results)}")

    if skipped_groups > 0 or stratified_groups > 0:
        print(f"\n‚ö†Ô∏è –°–¢–ê–¢–ò–°–¢–ò–ö–ê –û–ë–†–ê–ë–û–¢–ö–ò:")
        if skipped_groups > 0:
            print(f"   –ü—Ä–æ–ø—É—â–µ–Ω–æ –≥—Ä—É–ø–ø —Å None: {skipped_groups}")
            print(f"   –ü—Ä–æ–ø—É—â–µ–Ω–æ —Ç–æ–≤–∞—Ä–æ–≤ —Å None: {skipped_items}")
        if stratified_groups > 0:
            print(f"   –ü—Ä–∏–º–µ–Ω–µ–Ω–∞ —Å—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è: {stratified_groups} –≥—Ä—É–ø–ø")
            print(f"   –û—Ö–≤–∞—Ç —Ü–µ–Ω–æ–≤—ã—Ö –¥–∏–∞–ø–∞–∑–æ–Ω–æ–≤: –¥–µ—à—ë–≤—ã–µ, —Å—Ä–µ–¥–Ω–∏–µ, –¥–æ—Ä–æ–≥–∏–µ ‚úÖ")
        print(f"\nüí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: –£–ª—É—á—à–∏—Ç–µ regex –≤ product_matcher_improved.py")

    print("="*80)

    if not results:
        return pd.DataFrame()

    return pd.DataFrame(results)

# –ê–ª–∏–∞—Å –¥–ª—è –æ–±—Ä—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏

fast_find_comparable_products = find_comparable_products_safe


if __name__ == "__main__":
    print("–ú–æ–¥—É–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ find_comparable_products_safe()")